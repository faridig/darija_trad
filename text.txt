sft_mixture:


Dans un premier temps interroger l'api huggingface pour avoir les stats sous json data\darija_sft_mixture\statistics\dataset_statistics.py

puis tÃ©lÃ©charger les parquets sur azure data\darija_sft_mixture\parquet_download\parquet_downloader.py et analyse sur data\darija_sft_mixture\parquet_download\analyse_parquet.ipynb

ensuite nettoyage de ces parquets avec data\darija_sft_mixture\nettoyage\nettoyage_csv.py et export en data\darija_sft_mixture\nettoyage\donnees_brutes.csv et format json data\darija_sft_mixture\nettoyage\traductions_processed.json

analyse de csv avec data\darija_sft_mixture\nettoyage\analyse_csv.ipynb

scrapping: 

je gÃ©nere des questions en et fr avec api openai avec data\darija_scrapping\data_synthetique\generer_questions.py j'ai en export deux xlsx data\darija_scrapping\data_synthetique\questions_en.xlsx
data\darija_scrapping\data_synthetique\questions_fr.xlsx

puis je les utilise avec script data\darija_scrapping\scrapping.py pour faire le scrapping sur le site et j'ai en export data\darija_scrapping\translations.json




data\normalise_data.py prend les deux json et les normalisent, supprime les doublons. 

dans database\insert_data.py j'utilise la fonction principal de data\normalise_data.py  puis insert_data sert Ã  envoyer les donnÃ©es propres dans la bdd 

dans database\migrations il y a des fichiers sql pour :

001_create_translations.sql
Câ€™est la premiÃ¨re migration.

Elle sert Ã  crÃ©er la table translations.

Elle dÃ©finit la structure de base : colonnes, types, peut-Ãªtre clÃ©s primaires.

Câ€™est comme poser les fondations dâ€™une maison.

ğŸ”¹ 002_add_index_lang.sql
Ajoute probablement un index sur une ou plusieurs colonnes (source_lang, target_lang, etc.).

Pourquoi ? Pour accÃ©lÃ©rer les recherches dans ta base (par exemple : retrouver toutes les traductions en fr â†’ ar rapidement).

Câ€™est une optimisation, pas obligatoire pour que Ã§a marche, mais essentielle pour que Ã§a marche vite.

ğŸ”¹ 003_add_unique_constraint.sql
Ajoute une contrainte dâ€™unicitÃ© sur certaines colonnes (probablement les 4 champs source_lang, source_text, target_lang, target_text).

EmpÃªche lâ€™insertion de doublons.


(venv) âœ  database git:(bdd) âœ— sudo -u postgres psql -d darija_db  pour aller dans la bdd

api crud :    uvicorn api.data_api.main:app --reload

docker pour build : docker build -f api/data_api/Dockerfile -t my-api .


database\migrations\run_migrations.py lance database\migrations\001_create_translations.sql puis database\insert_data.py puis database\migrations\002_add_index_lang.sql puis database\migrations\003_add_unique_constraint.sql

