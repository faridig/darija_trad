sft_mixture:


Dans un premier temps interroger l'api huggingface pour avoir les stats sous json data\darija_sft_mixture\statistics\dataset_statistics.py

puis télécharger les parquets sur azure data\darija_sft_mixture\parquet_download\parquet_downloader.py et analyse sur data\darija_sft_mixture\parquet_download\analyse_parquet.ipynb

ensuite nettoyage de ces parquets avec data\darija_sft_mixture\nettoyage\nettoyage_csv.py et export en data\darija_sft_mixture\nettoyage\donnees_brutes.csv et format json data\darija_sft_mixture\nettoyage\traductions_processed.json

analyse de csv avec data\darija_sft_mixture\nettoyage\analyse_csv.ipynb

scrapping: 

je génere des questions en et fr avec api openai avec data\darija_scrapping\data_synthetique\generer_questions.py j'ai en export deux xlsx data\darija_scrapping\data_synthetique\questions_en.xlsx
data\darija_scrapping\data_synthetique\questions_fr.xlsx

puis je les utilise avec script data\darija_scrapping\scrapping.py pour faire le scrapping sur le site et j'ai en export data\darija_scrapping\translations.json




data\normalise_data.py prend les deux json et les normalisent, supprime les doublons. 

dans database\insert_data.py j'utilise la fonction principal de data\normalise_data.py  puis insert_data sert à envoyer les données propres dans la bdd 

dans database\migrations il y a des fichiers sql pour :

001_create_translations.sql
C’est la première migration.

Elle sert à créer la table translations.

Elle définit la structure de base : colonnes, types, peut-être clés primaires.

C’est comme poser les fondations d’une maison.

🔹 002_add_index_lang.sql
Ajoute probablement un index sur une ou plusieurs colonnes (source_lang, target_lang, etc.).

Pourquoi ? Pour accélérer les recherches dans ta base (par exemple : retrouver toutes les traductions en fr → ar rapidement).

C’est une optimisation, pas obligatoire pour que ça marche, mais essentielle pour que ça marche vite.

🔹 003_add_unique_constraint.sql
Ajoute une contrainte d’unicité sur certaines colonnes (probablement les 4 champs source_lang, source_text, target_lang, target_text).

Empêche l’insertion de doublons.


(venv) ➜  database git:(bdd) ✗ sudo -u postgres psql -d darija_db  pour aller dans la bdd

api crud :    uvicorn api.data_api.main:app --reload

docker pour build : docker build -f api/data_api/Dockerfile -t my-api .


database\migrations\run_migrations.py lance database\migrations\001_create_translations.sql puis database\insert_data.py puis database\migrations\002_add_index_lang.sql puis database\migrations\003_add_unique_constraint.sql

