{
  "best_global_step": 42000,
  "best_metric": 18.250874124919353,
  "best_model_checkpoint": "./nllb-darija-finetuned-lora/checkpoint-42000",
  "epoch": 2.962865420068475,
  "eval_steps": 1000,
  "global_step": 45000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006584145377929945,
      "grad_norm": 0.3380972445011139,
      "learning_rate": 0.0004989136160126415,
      "loss": 9.0885,
      "step": 100
    },
    {
      "epoch": 0.01316829075585989,
      "grad_norm": 0.2060510367155075,
      "learning_rate": 0.0004978162584496533,
      "loss": 7.0574,
      "step": 200
    },
    {
      "epoch": 0.019752436133789835,
      "grad_norm": 0.22542189061641693,
      "learning_rate": 0.0004967189008866649,
      "loss": 6.899,
      "step": 300
    },
    {
      "epoch": 0.02633658151171978,
      "grad_norm": 0.22762630879878998,
      "learning_rate": 0.0004956215433236765,
      "loss": 6.8832,
      "step": 400
    },
    {
      "epoch": 0.032920726889649726,
      "grad_norm": 0.35670366883277893,
      "learning_rate": 0.0004945241857606883,
      "loss": 6.8603,
      "step": 500
    },
    {
      "epoch": 0.03950487226757967,
      "grad_norm": 0.25016918778419495,
      "learning_rate": 0.0004934268281976999,
      "loss": 6.8635,
      "step": 600
    },
    {
      "epoch": 0.046089017645509614,
      "grad_norm": 0.21257154643535614,
      "learning_rate": 0.0004923294706347117,
      "loss": 6.7934,
      "step": 700
    },
    {
      "epoch": 0.05267316302343956,
      "grad_norm": 0.19044972956180573,
      "learning_rate": 0.0004912321130717233,
      "loss": 6.8319,
      "step": 800
    },
    {
      "epoch": 0.0592573084013695,
      "grad_norm": 0.20626334846019745,
      "learning_rate": 0.000490134755508735,
      "loss": 6.7926,
      "step": 900
    },
    {
      "epoch": 0.06584145377929945,
      "grad_norm": 0.23452933132648468,
      "learning_rate": 0.0004890373979457467,
      "loss": 6.8202,
      "step": 1000
    },
    {
      "epoch": 0.06584145377929945,
      "eval_bleu": 6.816181079389264,
      "eval_loss": 6.713735580444336,
      "eval_runtime": 247.5424,
      "eval_samples_per_second": 4.04,
      "eval_steps_per_second": 0.505,
      "step": 1000
    },
    {
      "epoch": 0.07242559915722939,
      "grad_norm": 0.22980362176895142,
      "learning_rate": 0.00048794004038275836,
      "loss": 6.7693,
      "step": 1100
    },
    {
      "epoch": 0.07900974453515934,
      "grad_norm": 0.2014348953962326,
      "learning_rate": 0.00048684268281977,
      "loss": 6.7975,
      "step": 1200
    },
    {
      "epoch": 0.08559388991308928,
      "grad_norm": 0.20374490320682526,
      "learning_rate": 0.0004857453252567817,
      "loss": 6.7461,
      "step": 1300
    },
    {
      "epoch": 0.09217803529101923,
      "grad_norm": 0.19152645766735077,
      "learning_rate": 0.00048464796769379337,
      "loss": 6.8259,
      "step": 1400
    },
    {
      "epoch": 0.09876218066894916,
      "grad_norm": 0.46170365810394287,
      "learning_rate": 0.00048355061013080505,
      "loss": 6.8046,
      "step": 1500
    },
    {
      "epoch": 0.10534632604687912,
      "grad_norm": 0.2300734966993332,
      "learning_rate": 0.0004824532525678167,
      "loss": 6.7407,
      "step": 1600
    },
    {
      "epoch": 0.11193047142480907,
      "grad_norm": 0.2956032156944275,
      "learning_rate": 0.00048135589500482843,
      "loss": 6.7833,
      "step": 1700
    },
    {
      "epoch": 0.118514616802739,
      "grad_norm": 0.1880386918783188,
      "learning_rate": 0.00048025853744184006,
      "loss": 6.7437,
      "step": 1800
    },
    {
      "epoch": 0.12509876218066895,
      "grad_norm": 0.24439936876296997,
      "learning_rate": 0.0004791611798788517,
      "loss": 6.7849,
      "step": 1900
    },
    {
      "epoch": 0.1316829075585989,
      "grad_norm": 0.1956501305103302,
      "learning_rate": 0.00047806382231586344,
      "loss": 6.7667,
      "step": 2000
    },
    {
      "epoch": 0.1316829075585989,
      "eval_bleu": 7.331548133119323,
      "eval_loss": 6.674820899963379,
      "eval_runtime": 174.8718,
      "eval_samples_per_second": 5.718,
      "eval_steps_per_second": 0.715,
      "step": 2000
    },
    {
      "epoch": 0.13826705293652883,
      "grad_norm": 0.21358560025691986,
      "learning_rate": 0.0004769664647528751,
      "loss": 6.7697,
      "step": 2100
    },
    {
      "epoch": 0.14485119831445878,
      "grad_norm": 0.23614276945590973,
      "learning_rate": 0.00047586910718988676,
      "loss": 6.7355,
      "step": 2200
    },
    {
      "epoch": 0.15143534369238873,
      "grad_norm": 0.2490862011909485,
      "learning_rate": 0.00047477174962689845,
      "loss": 6.7241,
      "step": 2300
    },
    {
      "epoch": 0.15801948907031868,
      "grad_norm": 0.24091939628124237,
      "learning_rate": 0.0004736743920639101,
      "loss": 6.7085,
      "step": 2400
    },
    {
      "epoch": 0.1646036344482486,
      "grad_norm": 0.2088617980480194,
      "learning_rate": 0.00047257703450092177,
      "loss": 6.7059,
      "step": 2500
    },
    {
      "epoch": 0.17118777982617855,
      "grad_norm": 0.3021564185619354,
      "learning_rate": 0.00047147967693793346,
      "loss": 6.7924,
      "step": 2600
    },
    {
      "epoch": 0.1777719252041085,
      "grad_norm": 0.2095077484846115,
      "learning_rate": 0.00047038231937494515,
      "loss": 6.7507,
      "step": 2700
    },
    {
      "epoch": 0.18435607058203846,
      "grad_norm": 0.25723427534103394,
      "learning_rate": 0.00046928496181195684,
      "loss": 6.7351,
      "step": 2800
    },
    {
      "epoch": 0.1909402159599684,
      "grad_norm": 0.2823590934276581,
      "learning_rate": 0.0004681876042489685,
      "loss": 6.6721,
      "step": 2900
    },
    {
      "epoch": 0.19752436133789833,
      "grad_norm": 0.24874050915241241,
      "learning_rate": 0.00046709024668598016,
      "loss": 6.7489,
      "step": 3000
    },
    {
      "epoch": 0.19752436133789833,
      "eval_bleu": 9.787623109801357,
      "eval_loss": 6.653610706329346,
      "eval_runtime": 160.2924,
      "eval_samples_per_second": 6.239,
      "eval_steps_per_second": 0.78,
      "step": 3000
    },
    {
      "epoch": 0.20410850671582828,
      "grad_norm": 0.2993871569633484,
      "learning_rate": 0.00046599288912299185,
      "loss": 6.7187,
      "step": 3100
    },
    {
      "epoch": 0.21069265209375823,
      "grad_norm": 0.26982390880584717,
      "learning_rate": 0.00046489553156000353,
      "loss": 6.6903,
      "step": 3200
    },
    {
      "epoch": 0.21727679747168818,
      "grad_norm": 0.21513158082962036,
      "learning_rate": 0.00046379817399701517,
      "loss": 6.6733,
      "step": 3300
    },
    {
      "epoch": 0.22386094284961813,
      "grad_norm": 0.21260331571102142,
      "learning_rate": 0.0004627008164340269,
      "loss": 6.6353,
      "step": 3400
    },
    {
      "epoch": 0.23044508822754806,
      "grad_norm": 0.25274723768234253,
      "learning_rate": 0.00046160345887103854,
      "loss": 6.7143,
      "step": 3500
    },
    {
      "epoch": 0.237029233605478,
      "grad_norm": 0.24689404666423798,
      "learning_rate": 0.00046050610130805023,
      "loss": 6.7235,
      "step": 3600
    },
    {
      "epoch": 0.24361337898340796,
      "grad_norm": 0.3541351556777954,
      "learning_rate": 0.0004594087437450619,
      "loss": 6.6879,
      "step": 3700
    },
    {
      "epoch": 0.2501975243613379,
      "grad_norm": 0.2001868188381195,
      "learning_rate": 0.00045831138618207355,
      "loss": 6.7335,
      "step": 3800
    },
    {
      "epoch": 0.25678166973926786,
      "grad_norm": 0.3653493821620941,
      "learning_rate": 0.00045721402861908524,
      "loss": 6.7273,
      "step": 3900
    },
    {
      "epoch": 0.2633658151171978,
      "grad_norm": 0.236233651638031,
      "learning_rate": 0.00045611667105609693,
      "loss": 6.7398,
      "step": 4000
    },
    {
      "epoch": 0.2633658151171978,
      "eval_bleu": 10.40558335427659,
      "eval_loss": 6.636392593383789,
      "eval_runtime": 143.6351,
      "eval_samples_per_second": 6.962,
      "eval_steps_per_second": 0.87,
      "step": 4000
    },
    {
      "epoch": 0.2699499604951277,
      "grad_norm": 0.2770576775074005,
      "learning_rate": 0.0004550193134931086,
      "loss": 6.7444,
      "step": 4100
    },
    {
      "epoch": 0.27653410587305766,
      "grad_norm": 0.30307725071907043,
      "learning_rate": 0.00045392195593012025,
      "loss": 6.6947,
      "step": 4200
    },
    {
      "epoch": 0.2831182512509876,
      "grad_norm": 0.17376750707626343,
      "learning_rate": 0.000452824598367132,
      "loss": 6.6694,
      "step": 4300
    },
    {
      "epoch": 0.28970239662891756,
      "grad_norm": 0.26941928267478943,
      "learning_rate": 0.0004517272408041436,
      "loss": 6.724,
      "step": 4400
    },
    {
      "epoch": 0.2962865420068475,
      "grad_norm": 0.3018241226673126,
      "learning_rate": 0.00045062988324115526,
      "loss": 6.6634,
      "step": 4500
    },
    {
      "epoch": 0.30287068738477746,
      "grad_norm": 0.3375532031059265,
      "learning_rate": 0.000449532525678167,
      "loss": 6.6743,
      "step": 4600
    },
    {
      "epoch": 0.3094548327627074,
      "grad_norm": 0.38439059257507324,
      "learning_rate": 0.00044843516811517864,
      "loss": 6.7139,
      "step": 4700
    },
    {
      "epoch": 0.31603897814063736,
      "grad_norm": 0.29383277893066406,
      "learning_rate": 0.0004473378105521904,
      "loss": 6.689,
      "step": 4800
    },
    {
      "epoch": 0.3226231235185673,
      "grad_norm": 0.1988884061574936,
      "learning_rate": 0.000446240452989202,
      "loss": 6.7505,
      "step": 4900
    },
    {
      "epoch": 0.3292072688964972,
      "grad_norm": 0.29046422243118286,
      "learning_rate": 0.00044514309542621365,
      "loss": 6.711,
      "step": 5000
    },
    {
      "epoch": 0.3292072688964972,
      "eval_bleu": 10.349142062588628,
      "eval_loss": 6.623805999755859,
      "eval_runtime": 152.15,
      "eval_samples_per_second": 6.572,
      "eval_steps_per_second": 0.822,
      "step": 5000
    },
    {
      "epoch": 0.33579141427442716,
      "grad_norm": 0.2570984959602356,
      "learning_rate": 0.0004440457378632254,
      "loss": 6.725,
      "step": 5100
    },
    {
      "epoch": 0.3423755596523571,
      "grad_norm": 0.2677218019962311,
      "learning_rate": 0.000442948380300237,
      "loss": 6.717,
      "step": 5200
    },
    {
      "epoch": 0.34895970503028706,
      "grad_norm": 0.2944205701351166,
      "learning_rate": 0.0004418510227372487,
      "loss": 6.6949,
      "step": 5300
    },
    {
      "epoch": 0.355543850408217,
      "grad_norm": 0.2946680784225464,
      "learning_rate": 0.0004407536651742604,
      "loss": 6.6375,
      "step": 5400
    },
    {
      "epoch": 0.36212799578614696,
      "grad_norm": 0.2282433658838272,
      "learning_rate": 0.0004396563076112721,
      "loss": 6.727,
      "step": 5500
    },
    {
      "epoch": 0.3687121411640769,
      "grad_norm": 0.22540652751922607,
      "learning_rate": 0.0004385589500482837,
      "loss": 6.7063,
      "step": 5600
    },
    {
      "epoch": 0.37529628654200686,
      "grad_norm": 0.3527560234069824,
      "learning_rate": 0.0004374615924852954,
      "loss": 6.7069,
      "step": 5700
    },
    {
      "epoch": 0.3818804319199368,
      "grad_norm": 0.18340252339839935,
      "learning_rate": 0.0004363642349223071,
      "loss": 6.7226,
      "step": 5800
    },
    {
      "epoch": 0.38846457729786676,
      "grad_norm": 0.26190993189811707,
      "learning_rate": 0.00043526687735931873,
      "loss": 6.73,
      "step": 5900
    },
    {
      "epoch": 0.39504872267579666,
      "grad_norm": 0.23356403410434723,
      "learning_rate": 0.00043416951979633047,
      "loss": 6.68,
      "step": 6000
    },
    {
      "epoch": 0.39504872267579666,
      "eval_bleu": 10.989026908899284,
      "eval_loss": 6.613522052764893,
      "eval_runtime": 154.8301,
      "eval_samples_per_second": 6.459,
      "eval_steps_per_second": 0.807,
      "step": 6000
    },
    {
      "epoch": 0.4016328680537266,
      "grad_norm": 0.3028929829597473,
      "learning_rate": 0.0004330721622333421,
      "loss": 6.6828,
      "step": 6100
    },
    {
      "epoch": 0.40821701343165656,
      "grad_norm": 0.3241410553455353,
      "learning_rate": 0.0004319748046703538,
      "loss": 6.6436,
      "step": 6200
    },
    {
      "epoch": 0.4148011588095865,
      "grad_norm": 0.3610300123691559,
      "learning_rate": 0.0004308774471073655,
      "loss": 6.7151,
      "step": 6300
    },
    {
      "epoch": 0.42138530418751646,
      "grad_norm": 0.3310297429561615,
      "learning_rate": 0.0004297800895443771,
      "loss": 6.6381,
      "step": 6400
    },
    {
      "epoch": 0.4279694495654464,
      "grad_norm": 0.2460019886493683,
      "learning_rate": 0.00042868273198138886,
      "loss": 6.65,
      "step": 6500
    },
    {
      "epoch": 0.43455359494337636,
      "grad_norm": 0.2567752003669739,
      "learning_rate": 0.0004275853744184005,
      "loss": 6.7467,
      "step": 6600
    },
    {
      "epoch": 0.4411377403213063,
      "grad_norm": 0.28834623098373413,
      "learning_rate": 0.0004264880168554122,
      "loss": 6.607,
      "step": 6700
    },
    {
      "epoch": 0.44772188569923627,
      "grad_norm": 0.25650057196617126,
      "learning_rate": 0.00042539065929242387,
      "loss": 6.6794,
      "step": 6800
    },
    {
      "epoch": 0.45430603107716616,
      "grad_norm": 0.2935248613357544,
      "learning_rate": 0.00042429330172943556,
      "loss": 6.6045,
      "step": 6900
    },
    {
      "epoch": 0.4608901764550961,
      "grad_norm": 0.2831285893917084,
      "learning_rate": 0.0004231959441664472,
      "loss": 6.6503,
      "step": 7000
    },
    {
      "epoch": 0.4608901764550961,
      "eval_bleu": 11.447287184226852,
      "eval_loss": 6.603689193725586,
      "eval_runtime": 151.8923,
      "eval_samples_per_second": 6.584,
      "eval_steps_per_second": 0.823,
      "step": 7000
    },
    {
      "epoch": 0.46747432183302606,
      "grad_norm": 0.312701940536499,
      "learning_rate": 0.0004220985866034589,
      "loss": 6.7042,
      "step": 7100
    },
    {
      "epoch": 0.474058467210956,
      "grad_norm": 0.29350546002388,
      "learning_rate": 0.00042100122904047057,
      "loss": 6.615,
      "step": 7200
    },
    {
      "epoch": 0.48064261258888596,
      "grad_norm": 0.20405465364456177,
      "learning_rate": 0.0004199038714774822,
      "loss": 6.6621,
      "step": 7300
    },
    {
      "epoch": 0.4872267579668159,
      "grad_norm": 0.33340689539909363,
      "learning_rate": 0.00041880651391449394,
      "loss": 6.6106,
      "step": 7400
    },
    {
      "epoch": 0.49381090334474587,
      "grad_norm": 0.34592652320861816,
      "learning_rate": 0.0004177091563515056,
      "loss": 6.6527,
      "step": 7500
    },
    {
      "epoch": 0.5003950487226758,
      "grad_norm": 0.2729986011981964,
      "learning_rate": 0.00041661179878851726,
      "loss": 6.6805,
      "step": 7600
    },
    {
      "epoch": 0.5069791941006058,
      "grad_norm": 0.2300282120704651,
      "learning_rate": 0.00041551444122552895,
      "loss": 6.6407,
      "step": 7700
    },
    {
      "epoch": 0.5135633394785357,
      "grad_norm": 0.27623018622398376,
      "learning_rate": 0.0004144170836625406,
      "loss": 6.6682,
      "step": 7800
    },
    {
      "epoch": 0.5201474848564657,
      "grad_norm": 0.23586241900920868,
      "learning_rate": 0.0004133197260995523,
      "loss": 6.6755,
      "step": 7900
    },
    {
      "epoch": 0.5267316302343956,
      "grad_norm": 0.23284266889095306,
      "learning_rate": 0.00041222236853656396,
      "loss": 6.6124,
      "step": 8000
    },
    {
      "epoch": 0.5267316302343956,
      "eval_bleu": 12.132760136949711,
      "eval_loss": 6.5944037437438965,
      "eval_runtime": 148.9654,
      "eval_samples_per_second": 6.713,
      "eval_steps_per_second": 0.839,
      "step": 8000
    },
    {
      "epoch": 0.5333157756123256,
      "grad_norm": 0.24950054287910461,
      "learning_rate": 0.00041113598454920554,
      "loss": 6.6704,
      "step": 8100
    },
    {
      "epoch": 0.5398999209902554,
      "grad_norm": 0.2143014371395111,
      "learning_rate": 0.00041003862698621717,
      "loss": 6.706,
      "step": 8200
    },
    {
      "epoch": 0.5464840663681854,
      "grad_norm": 0.262436181306839,
      "learning_rate": 0.0004089412694232289,
      "loss": 6.6547,
      "step": 8300
    },
    {
      "epoch": 0.5530682117461153,
      "grad_norm": 0.3118579387664795,
      "learning_rate": 0.00040784391186024055,
      "loss": 6.6699,
      "step": 8400
    },
    {
      "epoch": 0.5596523571240453,
      "grad_norm": 0.29673802852630615,
      "learning_rate": 0.0004067575278728821,
      "loss": 6.667,
      "step": 8500
    },
    {
      "epoch": 0.5662365025019752,
      "grad_norm": 0.2842652499675751,
      "learning_rate": 0.00040566017030989375,
      "loss": 6.6543,
      "step": 8600
    },
    {
      "epoch": 0.5728206478799052,
      "grad_norm": 0.2214510440826416,
      "learning_rate": 0.0004045628127469055,
      "loss": 6.7017,
      "step": 8700
    },
    {
      "epoch": 0.5794047932578351,
      "grad_norm": 0.32106688618659973,
      "learning_rate": 0.00040346545518391713,
      "loss": 6.6348,
      "step": 8800
    },
    {
      "epoch": 0.5859889386357651,
      "grad_norm": 0.241730198264122,
      "learning_rate": 0.0004023680976209288,
      "loss": 6.7057,
      "step": 8900
    },
    {
      "epoch": 0.592573084013695,
      "grad_norm": 0.2111300528049469,
      "learning_rate": 0.0004012707400579405,
      "loss": 6.6962,
      "step": 9000
    },
    {
      "epoch": 0.592573084013695,
      "eval_bleu": 12.39663576586387,
      "eval_loss": 6.5875468254089355,
      "eval_runtime": 142.3386,
      "eval_samples_per_second": 7.026,
      "eval_steps_per_second": 0.878,
      "step": 9000
    },
    {
      "epoch": 0.599157229391625,
      "grad_norm": 0.32486698031425476,
      "learning_rate": 0.00040017338249495214,
      "loss": 6.6514,
      "step": 9100
    },
    {
      "epoch": 0.6057413747695549,
      "grad_norm": 0.23973503708839417,
      "learning_rate": 0.00039907602493196383,
      "loss": 6.7055,
      "step": 9200
    },
    {
      "epoch": 0.6123255201474849,
      "grad_norm": 0.3245791494846344,
      "learning_rate": 0.0003979786673689755,
      "loss": 6.6142,
      "step": 9300
    },
    {
      "epoch": 0.6189096655254148,
      "grad_norm": 0.41952061653137207,
      "learning_rate": 0.0003968813098059872,
      "loss": 6.6928,
      "step": 9400
    },
    {
      "epoch": 0.6254938109033448,
      "grad_norm": 0.23696792125701904,
      "learning_rate": 0.00039578395224299884,
      "loss": 6.6793,
      "step": 9500
    },
    {
      "epoch": 0.6320779562812747,
      "grad_norm": 0.1665622591972351,
      "learning_rate": 0.0003946865946800106,
      "loss": 6.6539,
      "step": 9600
    },
    {
      "epoch": 0.6386621016592047,
      "grad_norm": 0.3175649642944336,
      "learning_rate": 0.0003935892371170222,
      "loss": 6.6701,
      "step": 9700
    },
    {
      "epoch": 0.6452462470371346,
      "grad_norm": 0.3459082245826721,
      "learning_rate": 0.00039249187955403385,
      "loss": 6.6389,
      "step": 9800
    },
    {
      "epoch": 0.6518303924150646,
      "grad_norm": 0.2739153802394867,
      "learning_rate": 0.0003913945219910456,
      "loss": 6.7097,
      "step": 9900
    },
    {
      "epoch": 0.6584145377929944,
      "grad_norm": 0.2769973576068878,
      "learning_rate": 0.0003902971644280572,
      "loss": 6.6871,
      "step": 10000
    },
    {
      "epoch": 0.6584145377929944,
      "eval_bleu": 12.326623346320842,
      "eval_loss": 6.580321788787842,
      "eval_runtime": 146.6263,
      "eval_samples_per_second": 6.82,
      "eval_steps_per_second": 0.853,
      "step": 10000
    },
    {
      "epoch": 0.6649986831709244,
      "grad_norm": 0.2570924460887909,
      "learning_rate": 0.0003891998068650689,
      "loss": 6.5764,
      "step": 10100
    },
    {
      "epoch": 0.6715828285488543,
      "grad_norm": 0.27927064895629883,
      "learning_rate": 0.0003881024493020806,
      "loss": 6.7004,
      "step": 10200
    },
    {
      "epoch": 0.6781669739267843,
      "grad_norm": 0.333520770072937,
      "learning_rate": 0.0003870050917390923,
      "loss": 6.6712,
      "step": 10300
    },
    {
      "epoch": 0.6847511193047142,
      "grad_norm": 0.24589227139949799,
      "learning_rate": 0.000385907734176104,
      "loss": 6.6741,
      "step": 10400
    },
    {
      "epoch": 0.6913352646826442,
      "grad_norm": 0.24908140301704407,
      "learning_rate": 0.0003848103766131156,
      "loss": 6.6745,
      "step": 10500
    },
    {
      "epoch": 0.6979194100605741,
      "grad_norm": 0.30904248356819153,
      "learning_rate": 0.0003837130190501273,
      "loss": 6.6492,
      "step": 10600
    },
    {
      "epoch": 0.7045035554385041,
      "grad_norm": 0.34169864654541016,
      "learning_rate": 0.00038262663506276887,
      "loss": 6.6693,
      "step": 10700
    },
    {
      "epoch": 0.711087700816434,
      "grad_norm": 0.2831953167915344,
      "learning_rate": 0.00038152927749978056,
      "loss": 6.6968,
      "step": 10800
    },
    {
      "epoch": 0.717671846194364,
      "grad_norm": 0.37174755334854126,
      "learning_rate": 0.0003804319199367922,
      "loss": 6.6587,
      "step": 10900
    },
    {
      "epoch": 0.7242559915722939,
      "grad_norm": 0.18954497575759888,
      "learning_rate": 0.0003793345623738039,
      "loss": 6.636,
      "step": 11000
    },
    {
      "epoch": 0.7242559915722939,
      "eval_bleu": 13.108579895920784,
      "eval_loss": 6.573942184448242,
      "eval_runtime": 144.8073,
      "eval_samples_per_second": 6.906,
      "eval_steps_per_second": 0.863,
      "step": 11000
    },
    {
      "epoch": 0.7308401369502239,
      "grad_norm": 0.3108372092247009,
      "learning_rate": 0.00037823720481081557,
      "loss": 6.6666,
      "step": 11100
    },
    {
      "epoch": 0.7374242823281538,
      "grad_norm": 0.39597487449645996,
      "learning_rate": 0.00037713984724782726,
      "loss": 6.6069,
      "step": 11200
    },
    {
      "epoch": 0.7440084277060838,
      "grad_norm": 0.2523396909236908,
      "learning_rate": 0.0003760424896848389,
      "loss": 6.6437,
      "step": 11300
    },
    {
      "epoch": 0.7505925730840137,
      "grad_norm": 0.22586920857429504,
      "learning_rate": 0.00037494513212185063,
      "loss": 6.5825,
      "step": 11400
    },
    {
      "epoch": 0.7571767184619437,
      "grad_norm": 0.2780565023422241,
      "learning_rate": 0.00037384777455886227,
      "loss": 6.6088,
      "step": 11500
    },
    {
      "epoch": 0.7637608638398736,
      "grad_norm": 0.35229364037513733,
      "learning_rate": 0.0003727504169958739,
      "loss": 6.5657,
      "step": 11600
    },
    {
      "epoch": 0.7703450092178036,
      "grad_norm": 0.2645929455757141,
      "learning_rate": 0.00037165305943288564,
      "loss": 6.646,
      "step": 11700
    },
    {
      "epoch": 0.7769291545957335,
      "grad_norm": 0.24770081043243408,
      "learning_rate": 0.0003705557018698973,
      "loss": 6.6786,
      "step": 11800
    },
    {
      "epoch": 0.7835132999736634,
      "grad_norm": 0.32713115215301514,
      "learning_rate": 0.00036945834430690896,
      "loss": 6.6704,
      "step": 11900
    },
    {
      "epoch": 0.7900974453515933,
      "grad_norm": 0.2297246754169464,
      "learning_rate": 0.00036836098674392065,
      "loss": 6.6937,
      "step": 12000
    },
    {
      "epoch": 0.7900974453515933,
      "eval_bleu": 13.332882047257026,
      "eval_loss": 6.569709777832031,
      "eval_runtime": 143.4656,
      "eval_samples_per_second": 6.97,
      "eval_steps_per_second": 0.871,
      "step": 12000
    },
    {
      "epoch": 0.7966815907295233,
      "grad_norm": 0.2556881904602051,
      "learning_rate": 0.0003672636291809323,
      "loss": 6.6044,
      "step": 12100
    },
    {
      "epoch": 0.8032657361074532,
      "grad_norm": 0.2395716905593872,
      "learning_rate": 0.00036616627161794403,
      "loss": 6.6202,
      "step": 12200
    },
    {
      "epoch": 0.8098498814853832,
      "grad_norm": 0.39773163199424744,
      "learning_rate": 0.00036506891405495566,
      "loss": 6.6329,
      "step": 12300
    },
    {
      "epoch": 0.8164340268633131,
      "grad_norm": 0.29090166091918945,
      "learning_rate": 0.00036397155649196735,
      "loss": 6.5955,
      "step": 12400
    },
    {
      "epoch": 0.8230181722412431,
      "grad_norm": 0.29116731882095337,
      "learning_rate": 0.00036287419892897904,
      "loss": 6.6968,
      "step": 12500
    },
    {
      "epoch": 0.829602317619173,
      "grad_norm": 0.2634288966655731,
      "learning_rate": 0.0003617768413659907,
      "loss": 6.641,
      "step": 12600
    },
    {
      "epoch": 0.836186462997103,
      "grad_norm": 0.33170074224472046,
      "learning_rate": 0.00036067948380300236,
      "loss": 6.6484,
      "step": 12700
    },
    {
      "epoch": 0.8427706083750329,
      "grad_norm": 0.32228338718414307,
      "learning_rate": 0.00035958212624001405,
      "loss": 6.6293,
      "step": 12800
    },
    {
      "epoch": 0.8493547537529629,
      "grad_norm": 0.32346513867378235,
      "learning_rate": 0.00035848476867702574,
      "loss": 6.6046,
      "step": 12900
    },
    {
      "epoch": 0.8559388991308928,
      "grad_norm": 0.27250799536705017,
      "learning_rate": 0.00035738741111403737,
      "loss": 6.6251,
      "step": 13000
    },
    {
      "epoch": 0.8559388991308928,
      "eval_bleu": 13.117896231702279,
      "eval_loss": 6.5625104904174805,
      "eval_runtime": 147.0204,
      "eval_samples_per_second": 6.802,
      "eval_steps_per_second": 0.85,
      "step": 13000
    },
    {
      "epoch": 0.8625230445088228,
      "grad_norm": 0.2706142067909241,
      "learning_rate": 0.0003562900535510491,
      "loss": 6.6336,
      "step": 13100
    },
    {
      "epoch": 0.8691071898867527,
      "grad_norm": 0.2550923526287079,
      "learning_rate": 0.00035519269598806075,
      "loss": 6.6925,
      "step": 13200
    },
    {
      "epoch": 0.8756913352646827,
      "grad_norm": 0.7913032174110413,
      "learning_rate": 0.00035409533842507243,
      "loss": 6.6052,
      "step": 13300
    },
    {
      "epoch": 0.8822754806426126,
      "grad_norm": 0.2387622892856598,
      "learning_rate": 0.00035300895443771395,
      "loss": 6.6118,
      "step": 13400
    },
    {
      "epoch": 0.8888596260205426,
      "grad_norm": 0.3575824499130249,
      "learning_rate": 0.0003519115968747257,
      "loss": 6.6096,
      "step": 13500
    },
    {
      "epoch": 0.8954437713984725,
      "grad_norm": 0.32140710949897766,
      "learning_rate": 0.00035081423931173733,
      "loss": 6.6035,
      "step": 13600
    },
    {
      "epoch": 0.9020279167764024,
      "grad_norm": 0.282329797744751,
      "learning_rate": 0.000349716881748749,
      "loss": 6.7361,
      "step": 13700
    },
    {
      "epoch": 0.9086120621543323,
      "grad_norm": 0.3367077708244324,
      "learning_rate": 0.0003486195241857607,
      "loss": 6.6114,
      "step": 13800
    },
    {
      "epoch": 0.9151962075322623,
      "grad_norm": 0.2608778774738312,
      "learning_rate": 0.00034752216662277234,
      "loss": 6.7098,
      "step": 13900
    },
    {
      "epoch": 0.9217803529101922,
      "grad_norm": 0.2856731712818146,
      "learning_rate": 0.0003464357826354139,
      "loss": 6.6112,
      "step": 14000
    },
    {
      "epoch": 0.9217803529101922,
      "eval_bleu": 13.497871393344736,
      "eval_loss": 6.557338237762451,
      "eval_runtime": 143.9002,
      "eval_samples_per_second": 6.949,
      "eval_steps_per_second": 0.869,
      "step": 14000
    },
    {
      "epoch": 0.9283644982881222,
      "grad_norm": 0.32578328251838684,
      "learning_rate": 0.00034533842507242566,
      "loss": 6.5726,
      "step": 14100
    },
    {
      "epoch": 0.9349486436660521,
      "grad_norm": 0.32116463780403137,
      "learning_rate": 0.0003442410675094373,
      "loss": 6.6641,
      "step": 14200
    },
    {
      "epoch": 0.9415327890439821,
      "grad_norm": 0.22636672854423523,
      "learning_rate": 0.0003431437099464489,
      "loss": 6.663,
      "step": 14300
    },
    {
      "epoch": 0.948116934421912,
      "grad_norm": 0.3239683210849762,
      "learning_rate": 0.00034204635238346067,
      "loss": 6.5936,
      "step": 14400
    },
    {
      "epoch": 0.954701079799842,
      "grad_norm": 0.34231460094451904,
      "learning_rate": 0.0003409489948204723,
      "loss": 6.6177,
      "step": 14500
    },
    {
      "epoch": 0.9612852251777719,
      "grad_norm": 0.34157538414001465,
      "learning_rate": 0.000339851637257484,
      "loss": 6.5835,
      "step": 14600
    },
    {
      "epoch": 0.9678693705557019,
      "grad_norm": 0.22696107625961304,
      "learning_rate": 0.0003387542796944957,
      "loss": 6.5731,
      "step": 14700
    },
    {
      "epoch": 0.9744535159336318,
      "grad_norm": 0.2642287313938141,
      "learning_rate": 0.00033765692213150736,
      "loss": 6.5917,
      "step": 14800
    },
    {
      "epoch": 0.9810376613115618,
      "grad_norm": 0.2957538068294525,
      "learning_rate": 0.000336559564568519,
      "loss": 6.5925,
      "step": 14900
    },
    {
      "epoch": 0.9876218066894917,
      "grad_norm": 0.1782452017068863,
      "learning_rate": 0.0003354622070055307,
      "loss": 6.6983,
      "step": 15000
    },
    {
      "epoch": 0.9876218066894917,
      "eval_bleu": 13.937795674328465,
      "eval_loss": 6.553701400756836,
      "eval_runtime": 147.3742,
      "eval_samples_per_second": 6.785,
      "eval_steps_per_second": 0.848,
      "step": 15000
    },
    {
      "epoch": 0.9942059520674217,
      "grad_norm": 0.19947823882102966,
      "learning_rate": 0.0003343648494425424,
      "loss": 6.6481,
      "step": 15100
    },
    {
      "epoch": 1.0007900974453516,
      "grad_norm": 0.3463136553764343,
      "learning_rate": 0.000333267491879554,
      "loss": 6.6438,
      "step": 15200
    },
    {
      "epoch": 1.0073742428232815,
      "grad_norm": 0.3093806207180023,
      "learning_rate": 0.00033217013431656575,
      "loss": 6.6623,
      "step": 15300
    },
    {
      "epoch": 1.0139583882012115,
      "grad_norm": 0.2529093027114868,
      "learning_rate": 0.0003310727767535774,
      "loss": 6.5994,
      "step": 15400
    },
    {
      "epoch": 1.0205425335791414,
      "grad_norm": 0.23251518607139587,
      "learning_rate": 0.000329975419190589,
      "loss": 6.6376,
      "step": 15500
    },
    {
      "epoch": 1.0271266789570714,
      "grad_norm": 0.3396387994289398,
      "learning_rate": 0.00032887806162760076,
      "loss": 6.6549,
      "step": 15600
    },
    {
      "epoch": 1.0337108243350013,
      "grad_norm": 0.366050660610199,
      "learning_rate": 0.0003277807040646124,
      "loss": 6.6096,
      "step": 15700
    },
    {
      "epoch": 1.0402949697129313,
      "grad_norm": 0.36303776502609253,
      "learning_rate": 0.00032668334650162414,
      "loss": 6.6223,
      "step": 15800
    },
    {
      "epoch": 1.0468791150908612,
      "grad_norm": 0.3605026304721832,
      "learning_rate": 0.00032558598893863577,
      "loss": 6.6053,
      "step": 15900
    },
    {
      "epoch": 1.0534632604687912,
      "grad_norm": 0.22448742389678955,
      "learning_rate": 0.00032448863137564746,
      "loss": 6.6371,
      "step": 16000
    },
    {
      "epoch": 1.0534632604687912,
      "eval_bleu": 13.960586555854507,
      "eval_loss": 6.550036907196045,
      "eval_runtime": 146.0318,
      "eval_samples_per_second": 6.848,
      "eval_steps_per_second": 0.856,
      "step": 16000
    },
    {
      "epoch": 1.060047405846721,
      "grad_norm": 0.3077647387981415,
      "learning_rate": 0.00032339127381265915,
      "loss": 6.6568,
      "step": 16100
    },
    {
      "epoch": 1.0666315512246511,
      "grad_norm": 0.2952687740325928,
      "learning_rate": 0.0003222939162496708,
      "loss": 6.5928,
      "step": 16200
    },
    {
      "epoch": 1.073215696602581,
      "grad_norm": 0.30766481161117554,
      "learning_rate": 0.00032119655868668247,
      "loss": 6.6713,
      "step": 16300
    },
    {
      "epoch": 1.079799841980511,
      "grad_norm": 0.2807566225528717,
      "learning_rate": 0.00032009920112369416,
      "loss": 6.6996,
      "step": 16400
    },
    {
      "epoch": 1.0863839873584409,
      "grad_norm": 0.255243182182312,
      "learning_rate": 0.00031900184356070584,
      "loss": 6.5878,
      "step": 16500
    },
    {
      "epoch": 1.0929681327363707,
      "grad_norm": 0.4297901690006256,
      "learning_rate": 0.0003179044859977175,
      "loss": 6.6,
      "step": 16600
    },
    {
      "epoch": 1.0995522781143008,
      "grad_norm": 0.2920163571834564,
      "learning_rate": 0.0003168071284347292,
      "loss": 6.6235,
      "step": 16700
    },
    {
      "epoch": 1.1061364234922306,
      "grad_norm": 0.3418653905391693,
      "learning_rate": 0.00031570977087174085,
      "loss": 6.5803,
      "step": 16800
    },
    {
      "epoch": 1.1127205688701607,
      "grad_norm": 0.2714952826499939,
      "learning_rate": 0.0003146124133087525,
      "loss": 6.6318,
      "step": 16900
    },
    {
      "epoch": 1.1193047142480905,
      "grad_norm": 0.419321745634079,
      "learning_rate": 0.00031351505574576423,
      "loss": 6.5984,
      "step": 17000
    },
    {
      "epoch": 1.1193047142480905,
      "eval_bleu": 14.250760703894631,
      "eval_loss": 6.5452351570129395,
      "eval_runtime": 145.0269,
      "eval_samples_per_second": 6.895,
      "eval_steps_per_second": 0.862,
      "step": 17000
    },
    {
      "epoch": 1.1258888596260206,
      "grad_norm": 0.26756665110588074,
      "learning_rate": 0.00031241769818277586,
      "loss": 6.6003,
      "step": 17100
    },
    {
      "epoch": 1.1324730050039504,
      "grad_norm": 0.32327502965927124,
      "learning_rate": 0.00031132034061978755,
      "loss": 6.628,
      "step": 17200
    },
    {
      "epoch": 1.1390571503818805,
      "grad_norm": 0.2455778867006302,
      "learning_rate": 0.00031022298305679924,
      "loss": 6.61,
      "step": 17300
    },
    {
      "epoch": 1.1456412957598103,
      "grad_norm": 0.32639431953430176,
      "learning_rate": 0.0003091256254938109,
      "loss": 6.6418,
      "step": 17400
    },
    {
      "epoch": 1.1522254411377404,
      "grad_norm": 0.3024616837501526,
      "learning_rate": 0.00030802826793082256,
      "loss": 6.5768,
      "step": 17500
    },
    {
      "epoch": 1.1588095865156702,
      "grad_norm": 0.3648102581501007,
      "learning_rate": 0.00030693091036783425,
      "loss": 6.578,
      "step": 17600
    },
    {
      "epoch": 1.1653937318936003,
      "grad_norm": 0.23463135957717896,
      "learning_rate": 0.00030583355280484594,
      "loss": 6.6311,
      "step": 17700
    },
    {
      "epoch": 1.1719778772715301,
      "grad_norm": 0.3168480694293976,
      "learning_rate": 0.0003047361952418576,
      "loss": 6.5536,
      "step": 17800
    },
    {
      "epoch": 1.1785620226494602,
      "grad_norm": 0.29613298177719116,
      "learning_rate": 0.0003036388376788693,
      "loss": 6.6051,
      "step": 17900
    },
    {
      "epoch": 1.18514616802739,
      "grad_norm": 0.3173808157444,
      "learning_rate": 0.00030254148011588095,
      "loss": 6.6061,
      "step": 18000
    },
    {
      "epoch": 1.18514616802739,
      "eval_bleu": 14.003821711301889,
      "eval_loss": 6.542213439941406,
      "eval_runtime": 153.9285,
      "eval_samples_per_second": 6.497,
      "eval_steps_per_second": 0.812,
      "step": 18000
    },
    {
      "epoch": 1.19173031340532,
      "grad_norm": 0.27275294065475464,
      "learning_rate": 0.0003014550961285225,
      "loss": 6.6063,
      "step": 18100
    },
    {
      "epoch": 1.19831445878325,
      "grad_norm": 0.2884882092475891,
      "learning_rate": 0.0003003577385655342,
      "loss": 6.5874,
      "step": 18200
    },
    {
      "epoch": 1.2048986041611798,
      "grad_norm": 0.2854704260826111,
      "learning_rate": 0.0002992603810025459,
      "loss": 6.5905,
      "step": 18300
    },
    {
      "epoch": 1.2114827495391098,
      "grad_norm": 0.2859055697917938,
      "learning_rate": 0.0002981739970151874,
      "loss": 6.5807,
      "step": 18400
    },
    {
      "epoch": 1.2180668949170397,
      "grad_norm": 0.2857547998428345,
      "learning_rate": 0.0002970766394521991,
      "loss": 6.6156,
      "step": 18500
    },
    {
      "epoch": 1.2246510402949697,
      "grad_norm": 0.34075215458869934,
      "learning_rate": 0.0002959792818892108,
      "loss": 6.601,
      "step": 18600
    },
    {
      "epoch": 1.2312351856728996,
      "grad_norm": 0.27936413884162903,
      "learning_rate": 0.0002948819243262225,
      "loss": 6.6525,
      "step": 18700
    },
    {
      "epoch": 1.2378193310508296,
      "grad_norm": 0.31931373476982117,
      "learning_rate": 0.0002937845667632341,
      "loss": 6.6194,
      "step": 18800
    },
    {
      "epoch": 1.2444034764287595,
      "grad_norm": 0.15329322218894958,
      "learning_rate": 0.00029268720920024586,
      "loss": 6.6327,
      "step": 18900
    },
    {
      "epoch": 1.2509876218066895,
      "grad_norm": 0.37823009490966797,
      "learning_rate": 0.0002915898516372575,
      "loss": 6.6219,
      "step": 19000
    },
    {
      "epoch": 1.2509876218066895,
      "eval_bleu": 14.379976485929099,
      "eval_loss": 6.539217948913574,
      "eval_runtime": 153.3342,
      "eval_samples_per_second": 6.522,
      "eval_steps_per_second": 0.815,
      "step": 19000
    },
    {
      "epoch": 1.2575717671846194,
      "grad_norm": 0.2510779798030853,
      "learning_rate": 0.0002904924940742691,
      "loss": 6.6563,
      "step": 19100
    },
    {
      "epoch": 1.2641559125625494,
      "grad_norm": 0.3874647915363312,
      "learning_rate": 0.00028939513651128087,
      "loss": 6.6182,
      "step": 19200
    },
    {
      "epoch": 1.2707400579404793,
      "grad_norm": 0.2840101420879364,
      "learning_rate": 0.0002882977789482925,
      "loss": 6.6425,
      "step": 19300
    },
    {
      "epoch": 1.2773242033184093,
      "grad_norm": 0.41291841864585876,
      "learning_rate": 0.0002872004213853042,
      "loss": 6.5984,
      "step": 19400
    },
    {
      "epoch": 1.2839083486963392,
      "grad_norm": 0.3275521695613861,
      "learning_rate": 0.0002861030638223159,
      "loss": 6.6574,
      "step": 19500
    },
    {
      "epoch": 1.290492494074269,
      "grad_norm": 0.1731036901473999,
      "learning_rate": 0.0002850057062593275,
      "loss": 6.6105,
      "step": 19600
    },
    {
      "epoch": 1.297076639452199,
      "grad_norm": 0.3184523284435272,
      "learning_rate": 0.00028390834869633925,
      "loss": 6.5863,
      "step": 19700
    },
    {
      "epoch": 1.3036607848301291,
      "grad_norm": 0.25948166847229004,
      "learning_rate": 0.0002828109911333509,
      "loss": 6.605,
      "step": 19800
    },
    {
      "epoch": 1.310244930208059,
      "grad_norm": 0.31093913316726685,
      "learning_rate": 0.0002817136335703626,
      "loss": 6.6404,
      "step": 19900
    },
    {
      "epoch": 1.3168290755859888,
      "grad_norm": 0.2574984133243561,
      "learning_rate": 0.00028061627600737426,
      "loss": 6.6184,
      "step": 20000
    },
    {
      "epoch": 1.3168290755859888,
      "eval_bleu": 14.936828103972246,
      "eval_loss": 6.536059379577637,
      "eval_runtime": 151.0071,
      "eval_samples_per_second": 6.622,
      "eval_steps_per_second": 0.828,
      "step": 20000
    },
    {
      "epoch": 1.323413220963919,
      "grad_norm": 0.2686326503753662,
      "learning_rate": 0.00027951891844438595,
      "loss": 6.5568,
      "step": 20100
    },
    {
      "epoch": 1.329997366341849,
      "grad_norm": 0.31290286779403687,
      "learning_rate": 0.0002784215608813976,
      "loss": 6.6183,
      "step": 20200
    },
    {
      "epoch": 1.3365815117197788,
      "grad_norm": 0.2932465076446533,
      "learning_rate": 0.00027732420331840927,
      "loss": 6.6302,
      "step": 20300
    },
    {
      "epoch": 1.3431656570977086,
      "grad_norm": 0.31371772289276123,
      "learning_rate": 0.00027623781933105085,
      "loss": 6.6086,
      "step": 20400
    },
    {
      "epoch": 1.3497498024756387,
      "grad_norm": 0.23377804458141327,
      "learning_rate": 0.00027514046176806253,
      "loss": 6.5929,
      "step": 20500
    },
    {
      "epoch": 1.3563339478535685,
      "grad_norm": 0.36585739254951477,
      "learning_rate": 0.00027404310420507417,
      "loss": 6.5995,
      "step": 20600
    },
    {
      "epoch": 1.3629180932314986,
      "grad_norm": 0.3259359896183014,
      "learning_rate": 0.00027294574664208586,
      "loss": 6.5981,
      "step": 20700
    },
    {
      "epoch": 1.3695022386094284,
      "grad_norm": 0.23723053932189941,
      "learning_rate": 0.00027184838907909754,
      "loss": 6.6018,
      "step": 20800
    },
    {
      "epoch": 1.3760863839873585,
      "grad_norm": 0.2873659133911133,
      "learning_rate": 0.0002707510315161092,
      "loss": 6.6178,
      "step": 20900
    },
    {
      "epoch": 1.3826705293652883,
      "grad_norm": 0.24555519223213196,
      "learning_rate": 0.0002696536739531209,
      "loss": 6.5797,
      "step": 21000
    },
    {
      "epoch": 1.3826705293652883,
      "eval_bleu": 14.986361697510148,
      "eval_loss": 6.534785270690918,
      "eval_runtime": 148.6686,
      "eval_samples_per_second": 6.726,
      "eval_steps_per_second": 0.841,
      "step": 21000
    },
    {
      "epoch": 1.3892546747432184,
      "grad_norm": 0.22205044329166412,
      "learning_rate": 0.00026855631639013255,
      "loss": 6.6411,
      "step": 21100
    },
    {
      "epoch": 1.3958388201211482,
      "grad_norm": 0.31237325072288513,
      "learning_rate": 0.00026745895882714424,
      "loss": 6.5737,
      "step": 21200
    },
    {
      "epoch": 1.4024229654990783,
      "grad_norm": 0.31795552372932434,
      "learning_rate": 0.00026636160126415593,
      "loss": 6.6223,
      "step": 21300
    },
    {
      "epoch": 1.4090071108770081,
      "grad_norm": 0.2682573199272156,
      "learning_rate": 0.00026526424370116756,
      "loss": 6.6305,
      "step": 21400
    },
    {
      "epoch": 1.4155912562549382,
      "grad_norm": 0.3535800576210022,
      "learning_rate": 0.0002641668861381793,
      "loss": 6.5811,
      "step": 21500
    },
    {
      "epoch": 1.422175401632868,
      "grad_norm": 0.303443044424057,
      "learning_rate": 0.00026306952857519094,
      "loss": 6.6246,
      "step": 21600
    },
    {
      "epoch": 1.4287595470107979,
      "grad_norm": 0.3783121407032013,
      "learning_rate": 0.00026197217101220263,
      "loss": 6.5814,
      "step": 21700
    },
    {
      "epoch": 1.435343692388728,
      "grad_norm": 0.30625566840171814,
      "learning_rate": 0.0002608748134492143,
      "loss": 6.5503,
      "step": 21800
    },
    {
      "epoch": 1.441927837766658,
      "grad_norm": 0.36074715852737427,
      "learning_rate": 0.000259777455886226,
      "loss": 6.5884,
      "step": 21900
    },
    {
      "epoch": 1.4485119831445878,
      "grad_norm": 0.3397265076637268,
      "learning_rate": 0.00025868009832323764,
      "loss": 6.5955,
      "step": 22000
    },
    {
      "epoch": 1.4485119831445878,
      "eval_bleu": 15.149035464687318,
      "eval_loss": 6.530874729156494,
      "eval_runtime": 140.6007,
      "eval_samples_per_second": 7.112,
      "eval_steps_per_second": 0.889,
      "step": 22000
    },
    {
      "epoch": 1.4550961285225177,
      "grad_norm": 0.3414391875267029,
      "learning_rate": 0.0002575827407602493,
      "loss": 6.6242,
      "step": 22100
    },
    {
      "epoch": 1.4616802739004477,
      "grad_norm": 0.2572405934333801,
      "learning_rate": 0.000256485383197261,
      "loss": 6.6099,
      "step": 22200
    },
    {
      "epoch": 1.4682644192783776,
      "grad_norm": 0.32486477494239807,
      "learning_rate": 0.00025538802563427265,
      "loss": 6.6066,
      "step": 22300
    },
    {
      "epoch": 1.4748485646563076,
      "grad_norm": 0.3255738615989685,
      "learning_rate": 0.0002542906680712844,
      "loss": 6.5917,
      "step": 22400
    },
    {
      "epoch": 1.4814327100342375,
      "grad_norm": 0.3518535792827606,
      "learning_rate": 0.000253193310508296,
      "loss": 6.6026,
      "step": 22500
    },
    {
      "epoch": 1.4880168554121675,
      "grad_norm": 0.3272401690483093,
      "learning_rate": 0.00025209595294530766,
      "loss": 6.5647,
      "step": 22600
    },
    {
      "epoch": 1.4946010007900974,
      "grad_norm": 0.3389243185520172,
      "learning_rate": 0.0002509985953823194,
      "loss": 6.5434,
      "step": 22700
    },
    {
      "epoch": 1.5011851461680275,
      "grad_norm": 0.2933201491832733,
      "learning_rate": 0.00024990123781933103,
      "loss": 6.6217,
      "step": 22800
    },
    {
      "epoch": 1.5077692915459573,
      "grad_norm": 0.293018639087677,
      "learning_rate": 0.0002488038802563427,
      "loss": 6.5735,
      "step": 22900
    },
    {
      "epoch": 1.5143534369238871,
      "grad_norm": 0.41568663716316223,
      "learning_rate": 0.0002477065226933544,
      "loss": 6.6389,
      "step": 23000
    },
    {
      "epoch": 1.5143534369238871,
      "eval_bleu": 15.672661095848264,
      "eval_loss": 6.528792858123779,
      "eval_runtime": 138.6541,
      "eval_samples_per_second": 7.212,
      "eval_steps_per_second": 0.902,
      "step": 23000
    },
    {
      "epoch": 1.5209375823018172,
      "grad_norm": 0.2677422761917114,
      "learning_rate": 0.0002466091651303661,
      "loss": 6.6223,
      "step": 23100
    },
    {
      "epoch": 1.5275217276797473,
      "grad_norm": 0.23142032325267792,
      "learning_rate": 0.0002455118075673778,
      "loss": 6.6033,
      "step": 23200
    },
    {
      "epoch": 1.534105873057677,
      "grad_norm": 0.33448055386543274,
      "learning_rate": 0.0002444144500043894,
      "loss": 6.578,
      "step": 23300
    },
    {
      "epoch": 1.540690018435607,
      "grad_norm": 0.3856872022151947,
      "learning_rate": 0.0002433170924414011,
      "loss": 6.6331,
      "step": 23400
    },
    {
      "epoch": 1.547274163813537,
      "grad_norm": 0.34483376145362854,
      "learning_rate": 0.0002422197348784128,
      "loss": 6.5808,
      "step": 23500
    },
    {
      "epoch": 1.553858309191467,
      "grad_norm": 0.3286100924015045,
      "learning_rate": 0.00024112237731542446,
      "loss": 6.6262,
      "step": 23600
    },
    {
      "epoch": 1.560442454569397,
      "grad_norm": 0.3202846646308899,
      "learning_rate": 0.00024002501975243614,
      "loss": 6.5797,
      "step": 23700
    },
    {
      "epoch": 1.5670265999473267,
      "grad_norm": 0.28883758187294006,
      "learning_rate": 0.0002389276621894478,
      "loss": 6.5596,
      "step": 23800
    },
    {
      "epoch": 1.5736107453252568,
      "grad_norm": 0.23784683644771576,
      "learning_rate": 0.0002378303046264595,
      "loss": 6.6804,
      "step": 23900
    },
    {
      "epoch": 1.5801948907031869,
      "grad_norm": 0.25367021560668945,
      "learning_rate": 0.00023674392063910104,
      "loss": 6.5641,
      "step": 24000
    },
    {
      "epoch": 1.5801948907031869,
      "eval_bleu": 15.833315126077041,
      "eval_loss": 6.525953769683838,
      "eval_runtime": 137.3722,
      "eval_samples_per_second": 7.279,
      "eval_steps_per_second": 0.91,
      "step": 24000
    },
    {
      "epoch": 1.5867790360811167,
      "grad_norm": 0.3915531635284424,
      "learning_rate": 0.00023564656307611273,
      "loss": 6.5988,
      "step": 24100
    },
    {
      "epoch": 1.5933631814590465,
      "grad_norm": 0.3268298804759979,
      "learning_rate": 0.0002345492055131244,
      "loss": 6.628,
      "step": 24200
    },
    {
      "epoch": 1.5999473268369766,
      "grad_norm": 0.2627929449081421,
      "learning_rate": 0.00023345184795013608,
      "loss": 6.572,
      "step": 24300
    },
    {
      "epoch": 1.6065314722149067,
      "grad_norm": 0.2926206886768341,
      "learning_rate": 0.00023235449038714776,
      "loss": 6.6324,
      "step": 24400
    },
    {
      "epoch": 1.6131156175928365,
      "grad_norm": 0.48553261160850525,
      "learning_rate": 0.00023125713282415943,
      "loss": 6.5615,
      "step": 24500
    },
    {
      "epoch": 1.6196997629707663,
      "grad_norm": 0.26587289571762085,
      "learning_rate": 0.0002301597752611711,
      "loss": 6.6115,
      "step": 24600
    },
    {
      "epoch": 1.6262839083486962,
      "grad_norm": 0.24187138676643372,
      "learning_rate": 0.00022906241769818277,
      "loss": 6.6091,
      "step": 24700
    },
    {
      "epoch": 1.6328680537266262,
      "grad_norm": 0.32650279998779297,
      "learning_rate": 0.00022796506013519446,
      "loss": 6.5647,
      "step": 24800
    },
    {
      "epoch": 1.6394521991045563,
      "grad_norm": 0.31535080075263977,
      "learning_rate": 0.00022686770257220612,
      "loss": 6.6709,
      "step": 24900
    },
    {
      "epoch": 1.6460363444824861,
      "grad_norm": 0.3212659955024719,
      "learning_rate": 0.0002257703450092178,
      "loss": 6.591,
      "step": 25000
    },
    {
      "epoch": 1.6460363444824861,
      "eval_bleu": 15.645614378772576,
      "eval_loss": 6.5281829833984375,
      "eval_runtime": 142.5281,
      "eval_samples_per_second": 7.016,
      "eval_steps_per_second": 0.877,
      "step": 25000
    },
    {
      "epoch": 1.652620489860416,
      "grad_norm": 0.35962381958961487,
      "learning_rate": 0.0002246729874462295,
      "loss": 6.5863,
      "step": 25100
    },
    {
      "epoch": 1.659204635238346,
      "grad_norm": 0.2790636718273163,
      "learning_rate": 0.00022357562988324116,
      "loss": 6.6104,
      "step": 25200
    },
    {
      "epoch": 1.665788780616276,
      "grad_norm": 0.28591400384902954,
      "learning_rate": 0.00022247827232025282,
      "loss": 6.6101,
      "step": 25300
    },
    {
      "epoch": 1.672372925994206,
      "grad_norm": 0.3260592222213745,
      "learning_rate": 0.0002213918883328944,
      "loss": 6.6197,
      "step": 25400
    },
    {
      "epoch": 1.6789570713721358,
      "grad_norm": 0.30926257371902466,
      "learning_rate": 0.00022029453076990608,
      "loss": 6.5409,
      "step": 25500
    },
    {
      "epoch": 1.6855412167500659,
      "grad_norm": 0.29539281129837036,
      "learning_rate": 0.00021920814678254763,
      "loss": 6.5985,
      "step": 25600
    },
    {
      "epoch": 1.692125362127996,
      "grad_norm": 0.29218485951423645,
      "learning_rate": 0.00021811078921955932,
      "loss": 6.5836,
      "step": 25700
    },
    {
      "epoch": 1.6987095075059258,
      "grad_norm": 0.3324996829032898,
      "learning_rate": 0.00021701343165657098,
      "loss": 6.5341,
      "step": 25800
    },
    {
      "epoch": 1.7052936528838556,
      "grad_norm": 0.28722870349884033,
      "learning_rate": 0.00021591607409358267,
      "loss": 6.5929,
      "step": 25900
    },
    {
      "epoch": 1.7118777982617857,
      "grad_norm": 0.3602132499217987,
      "learning_rate": 0.00021481871653059435,
      "loss": 6.5962,
      "step": 26000
    },
    {
      "epoch": 1.7118777982617857,
      "eval_bleu": 16.117058009019168,
      "eval_loss": 6.528033256530762,
      "eval_runtime": 140.4972,
      "eval_samples_per_second": 7.118,
      "eval_steps_per_second": 0.89,
      "step": 26000
    },
    {
      "epoch": 1.7184619436397157,
      "grad_norm": 0.35423728823661804,
      "learning_rate": 0.000213721358967606,
      "loss": 6.6643,
      "step": 26100
    },
    {
      "epoch": 1.7250460890176456,
      "grad_norm": 0.2963985204696655,
      "learning_rate": 0.00021262400140461768,
      "loss": 6.5784,
      "step": 26200
    },
    {
      "epoch": 1.7316302343955754,
      "grad_norm": 0.30611738562583923,
      "learning_rate": 0.00021152664384162936,
      "loss": 6.6085,
      "step": 26300
    },
    {
      "epoch": 1.7382143797735052,
      "grad_norm": 0.29078418016433716,
      "learning_rate": 0.00021042928627864103,
      "loss": 6.5853,
      "step": 26400
    },
    {
      "epoch": 1.7447985251514353,
      "grad_norm": 0.30480778217315674,
      "learning_rate": 0.0002093319287156527,
      "loss": 6.5794,
      "step": 26500
    },
    {
      "epoch": 1.7513826705293654,
      "grad_norm": 0.34598222374916077,
      "learning_rate": 0.0002082345711526644,
      "loss": 6.5703,
      "step": 26600
    },
    {
      "epoch": 1.7579668159072952,
      "grad_norm": 0.34549617767333984,
      "learning_rate": 0.0002071372135896761,
      "loss": 6.6528,
      "step": 26700
    },
    {
      "epoch": 1.764550961285225,
      "grad_norm": 0.29207170009613037,
      "learning_rate": 0.00020603985602668772,
      "loss": 6.591,
      "step": 26800
    },
    {
      "epoch": 1.771135106663155,
      "grad_norm": 0.3276121914386749,
      "learning_rate": 0.0002049424984636994,
      "loss": 6.5892,
      "step": 26900
    },
    {
      "epoch": 1.7777192520410852,
      "grad_norm": 0.46860334277153015,
      "learning_rate": 0.0002038451409007111,
      "loss": 6.5887,
      "step": 27000
    },
    {
      "epoch": 1.7777192520410852,
      "eval_bleu": 16.45980074289012,
      "eval_loss": 6.52003288269043,
      "eval_runtime": 143.3491,
      "eval_samples_per_second": 6.976,
      "eval_steps_per_second": 0.872,
      "step": 27000
    },
    {
      "epoch": 1.784303397419015,
      "grad_norm": 0.29006168246269226,
      "learning_rate": 0.00020274778333772276,
      "loss": 6.6094,
      "step": 27100
    },
    {
      "epoch": 1.7908875427969448,
      "grad_norm": 0.3529830276966095,
      "learning_rate": 0.00020165042577473445,
      "loss": 6.6501,
      "step": 27200
    },
    {
      "epoch": 1.797471688174875,
      "grad_norm": 0.2780817151069641,
      "learning_rate": 0.00020055306821174614,
      "loss": 6.5658,
      "step": 27300
    },
    {
      "epoch": 1.804055833552805,
      "grad_norm": 0.3325495719909668,
      "learning_rate": 0.00019945571064875777,
      "loss": 6.5553,
      "step": 27400
    },
    {
      "epoch": 1.8106399789307348,
      "grad_norm": 0.2893218398094177,
      "learning_rate": 0.00019835835308576946,
      "loss": 6.6271,
      "step": 27500
    },
    {
      "epoch": 1.8172241243086646,
      "grad_norm": 0.3463432192802429,
      "learning_rate": 0.00019726099552278115,
      "loss": 6.5914,
      "step": 27600
    },
    {
      "epoch": 1.8238082696865947,
      "grad_norm": 0.36819377541542053,
      "learning_rate": 0.00019616363795979283,
      "loss": 6.6181,
      "step": 27700
    },
    {
      "epoch": 1.8303924150645248,
      "grad_norm": 0.3038223087787628,
      "learning_rate": 0.0001950662803968045,
      "loss": 6.598,
      "step": 27800
    },
    {
      "epoch": 1.8369765604424546,
      "grad_norm": 0.28814390301704407,
      "learning_rate": 0.00019396892283381618,
      "loss": 6.6423,
      "step": 27900
    },
    {
      "epoch": 1.8435607058203844,
      "grad_norm": 0.4211699366569519,
      "learning_rate": 0.00019287156527082787,
      "loss": 6.6074,
      "step": 28000
    },
    {
      "epoch": 1.8435607058203844,
      "eval_bleu": 16.209704873222748,
      "eval_loss": 6.518409252166748,
      "eval_runtime": 140.7097,
      "eval_samples_per_second": 7.107,
      "eval_steps_per_second": 0.888,
      "step": 28000
    },
    {
      "epoch": 1.8501448511983145,
      "grad_norm": 0.27114805579185486,
      "learning_rate": 0.0001917742077078395,
      "loss": 6.6698,
      "step": 28100
    },
    {
      "epoch": 1.8567289965762444,
      "grad_norm": 0.3258855640888214,
      "learning_rate": 0.0001906768501448512,
      "loss": 6.5533,
      "step": 28200
    },
    {
      "epoch": 1.8633131419541744,
      "grad_norm": 0.23762300610542297,
      "learning_rate": 0.00018957949258186288,
      "loss": 6.6326,
      "step": 28300
    },
    {
      "epoch": 1.8698972873321043,
      "grad_norm": 0.3973158895969391,
      "learning_rate": 0.00018848213501887457,
      "loss": 6.6056,
      "step": 28400
    },
    {
      "epoch": 1.876481432710034,
      "grad_norm": 0.36402595043182373,
      "learning_rate": 0.00018738477745588623,
      "loss": 6.6126,
      "step": 28500
    },
    {
      "epoch": 1.8830655780879642,
      "grad_norm": 0.2970982491970062,
      "learning_rate": 0.00018628741989289792,
      "loss": 6.5881,
      "step": 28600
    },
    {
      "epoch": 1.8896497234658942,
      "grad_norm": 0.40226438641548157,
      "learning_rate": 0.00018519006232990958,
      "loss": 6.6244,
      "step": 28700
    },
    {
      "epoch": 1.896233868843824,
      "grad_norm": 0.24748045206069946,
      "learning_rate": 0.00018409270476692124,
      "loss": 6.595,
      "step": 28800
    },
    {
      "epoch": 1.902818014221754,
      "grad_norm": 0.4136658012866974,
      "learning_rate": 0.00018299534720393293,
      "loss": 6.5181,
      "step": 28900
    },
    {
      "epoch": 1.909402159599684,
      "grad_norm": 0.3049013316631317,
      "learning_rate": 0.00018189798964094462,
      "loss": 6.5551,
      "step": 29000
    },
    {
      "epoch": 1.909402159599684,
      "eval_bleu": 16.825589271102587,
      "eval_loss": 6.51617956161499,
      "eval_runtime": 146.1519,
      "eval_samples_per_second": 6.842,
      "eval_steps_per_second": 0.855,
      "step": 29000
    },
    {
      "epoch": 1.915986304977614,
      "grad_norm": 0.32851043343544006,
      "learning_rate": 0.00018080063207795628,
      "loss": 6.5386,
      "step": 29100
    },
    {
      "epoch": 1.9225704503555439,
      "grad_norm": 0.24581344425678253,
      "learning_rate": 0.00017970327451496796,
      "loss": 6.5733,
      "step": 29200
    },
    {
      "epoch": 1.9291545957334737,
      "grad_norm": 0.2530311644077301,
      "learning_rate": 0.00017860591695197965,
      "loss": 6.5837,
      "step": 29300
    },
    {
      "epoch": 1.9357387411114038,
      "grad_norm": 0.23074018955230713,
      "learning_rate": 0.00017750855938899131,
      "loss": 6.6007,
      "step": 29400
    },
    {
      "epoch": 1.9423228864893338,
      "grad_norm": 0.2677481174468994,
      "learning_rate": 0.00017641120182600297,
      "loss": 6.6028,
      "step": 29500
    },
    {
      "epoch": 1.9489070318672637,
      "grad_norm": 0.26880496740341187,
      "learning_rate": 0.00017531384426301466,
      "loss": 6.6099,
      "step": 29600
    },
    {
      "epoch": 1.9554911772451935,
      "grad_norm": 0.27100205421447754,
      "learning_rate": 0.00017421648670002635,
      "loss": 6.5743,
      "step": 29700
    },
    {
      "epoch": 1.9620753226231236,
      "grad_norm": 0.3600383996963501,
      "learning_rate": 0.000173119129137038,
      "loss": 6.631,
      "step": 29800
    },
    {
      "epoch": 1.9686594680010536,
      "grad_norm": 0.2905300557613373,
      "learning_rate": 0.0001720217715740497,
      "loss": 6.5701,
      "step": 29900
    },
    {
      "epoch": 1.9752436133789835,
      "grad_norm": 0.21289841830730438,
      "learning_rate": 0.0001709244140110614,
      "loss": 6.5902,
      "step": 30000
    },
    {
      "epoch": 1.9752436133789835,
      "eval_bleu": 16.578400915270073,
      "eval_loss": 6.514288902282715,
      "eval_runtime": 147.5476,
      "eval_samples_per_second": 6.777,
      "eval_steps_per_second": 0.847,
      "step": 30000
    },
    {
      "epoch": 1.9818277587569133,
      "grad_norm": 0.3318553566932678,
      "learning_rate": 0.00016982705644807302,
      "loss": 6.5794,
      "step": 30100
    },
    {
      "epoch": 1.9884119041348431,
      "grad_norm": 0.21491128206253052,
      "learning_rate": 0.0001687296988850847,
      "loss": 6.5951,
      "step": 30200
    },
    {
      "epoch": 1.9949960495127732,
      "grad_norm": 0.3566771447658539,
      "learning_rate": 0.0001676323413220964,
      "loss": 6.5374,
      "step": 30300
    },
    {
      "epoch": 2.0015801948907033,
      "grad_norm": 0.3817509412765503,
      "learning_rate": 0.00016653498375910809,
      "loss": 6.5866,
      "step": 30400
    },
    {
      "epoch": 2.008164340268633,
      "grad_norm": 0.3020392656326294,
      "learning_rate": 0.00016543762619611975,
      "loss": 6.6217,
      "step": 30500
    },
    {
      "epoch": 2.014748485646563,
      "grad_norm": 0.3589273691177368,
      "learning_rate": 0.00016434026863313143,
      "loss": 6.6142,
      "step": 30600
    },
    {
      "epoch": 2.0213326310244932,
      "grad_norm": 0.24622926115989685,
      "learning_rate": 0.0001632429110701431,
      "loss": 6.6009,
      "step": 30700
    },
    {
      "epoch": 2.027916776402423,
      "grad_norm": 0.3400528132915497,
      "learning_rate": 0.00016214555350715476,
      "loss": 6.5638,
      "step": 30800
    },
    {
      "epoch": 2.034500921780353,
      "grad_norm": 0.4013582468032837,
      "learning_rate": 0.00016104819594416644,
      "loss": 6.6009,
      "step": 30900
    },
    {
      "epoch": 2.0410850671582828,
      "grad_norm": 0.324627548456192,
      "learning_rate": 0.00015995083838117813,
      "loss": 6.58,
      "step": 31000
    },
    {
      "epoch": 2.0410850671582828,
      "eval_bleu": 17.0438214030542,
      "eval_loss": 6.514113903045654,
      "eval_runtime": 146.3852,
      "eval_samples_per_second": 6.831,
      "eval_steps_per_second": 0.854,
      "step": 31000
    },
    {
      "epoch": 2.0476692125362126,
      "grad_norm": 0.3106609284877777,
      "learning_rate": 0.00015885348081818982,
      "loss": 6.58,
      "step": 31100
    },
    {
      "epoch": 2.054253357914143,
      "grad_norm": 0.29872292280197144,
      "learning_rate": 0.00015775612325520148,
      "loss": 6.619,
      "step": 31200
    },
    {
      "epoch": 2.0608375032920727,
      "grad_norm": 0.3396633267402649,
      "learning_rate": 0.00015665876569221317,
      "loss": 6.6136,
      "step": 31300
    },
    {
      "epoch": 2.0674216486700026,
      "grad_norm": 0.33759164810180664,
      "learning_rate": 0.00015556140812922483,
      "loss": 6.6205,
      "step": 31400
    },
    {
      "epoch": 2.0740057940479324,
      "grad_norm": 0.3198598325252533,
      "learning_rate": 0.0001544640505662365,
      "loss": 6.5888,
      "step": 31500
    },
    {
      "epoch": 2.0805899394258627,
      "grad_norm": 0.25748634338378906,
      "learning_rate": 0.00015337766657887806,
      "loss": 6.5585,
      "step": 31600
    },
    {
      "epoch": 2.0871740848037925,
      "grad_norm": 0.34743696451187134,
      "learning_rate": 0.00015228030901588975,
      "loss": 6.5495,
      "step": 31700
    },
    {
      "epoch": 2.0937582301817224,
      "grad_norm": 0.429685115814209,
      "learning_rate": 0.00015118295145290141,
      "loss": 6.5994,
      "step": 31800
    },
    {
      "epoch": 2.100342375559652,
      "grad_norm": 0.2905528247356415,
      "learning_rate": 0.00015008559388991307,
      "loss": 6.5934,
      "step": 31900
    },
    {
      "epoch": 2.1069265209375825,
      "grad_norm": 0.31973209977149963,
      "learning_rate": 0.00014898823632692476,
      "loss": 6.6289,
      "step": 32000
    },
    {
      "epoch": 2.1069265209375825,
      "eval_bleu": 17.191186417946867,
      "eval_loss": 6.510920524597168,
      "eval_runtime": 145.3302,
      "eval_samples_per_second": 6.881,
      "eval_steps_per_second": 0.86,
      "step": 32000
    },
    {
      "epoch": 2.1135106663155123,
      "grad_norm": 0.33873844146728516,
      "learning_rate": 0.00014789087876393645,
      "loss": 6.6079,
      "step": 32100
    },
    {
      "epoch": 2.120094811693442,
      "grad_norm": 0.2910178303718567,
      "learning_rate": 0.00014679352120094814,
      "loss": 6.6282,
      "step": 32200
    },
    {
      "epoch": 2.126678957071372,
      "grad_norm": 0.26499396562576294,
      "learning_rate": 0.0001456961636379598,
      "loss": 6.5594,
      "step": 32300
    },
    {
      "epoch": 2.1332631024493023,
      "grad_norm": 0.32636433839797974,
      "learning_rate": 0.00014459880607497146,
      "loss": 6.6135,
      "step": 32400
    },
    {
      "epoch": 2.139847247827232,
      "grad_norm": 0.39722293615341187,
      "learning_rate": 0.00014350144851198315,
      "loss": 6.5889,
      "step": 32500
    },
    {
      "epoch": 2.146431393205162,
      "grad_norm": 0.31520676612854004,
      "learning_rate": 0.0001424040909489948,
      "loss": 6.6207,
      "step": 32600
    },
    {
      "epoch": 2.153015538583092,
      "grad_norm": 0.3248080313205719,
      "learning_rate": 0.0001413067333860065,
      "loss": 6.6322,
      "step": 32700
    },
    {
      "epoch": 2.159599683961022,
      "grad_norm": 0.318447083234787,
      "learning_rate": 0.00014020937582301819,
      "loss": 6.5152,
      "step": 32800
    },
    {
      "epoch": 2.166183829338952,
      "grad_norm": 0.27497607469558716,
      "learning_rate": 0.00013911201826002985,
      "loss": 6.5754,
      "step": 32900
    },
    {
      "epoch": 2.1727679747168818,
      "grad_norm": 0.30845674872398376,
      "learning_rate": 0.00013801466069704153,
      "loss": 6.5617,
      "step": 33000
    },
    {
      "epoch": 2.1727679747168818,
      "eval_bleu": 17.599930487051022,
      "eval_loss": 6.509603500366211,
      "eval_runtime": 140.3876,
      "eval_samples_per_second": 7.123,
      "eval_steps_per_second": 0.89,
      "step": 33000
    },
    {
      "epoch": 2.1793521200948116,
      "grad_norm": 0.3298637568950653,
      "learning_rate": 0.0001369173031340532,
      "loss": 6.5947,
      "step": 33100
    },
    {
      "epoch": 2.1859362654727414,
      "grad_norm": 0.2993270754814148,
      "learning_rate": 0.00013581994557106488,
      "loss": 6.5645,
      "step": 33200
    },
    {
      "epoch": 2.1925204108506717,
      "grad_norm": 0.300312876701355,
      "learning_rate": 0.00013472258800807654,
      "loss": 6.5723,
      "step": 33300
    },
    {
      "epoch": 2.1991045562286016,
      "grad_norm": 0.2610218822956085,
      "learning_rate": 0.00013362523044508823,
      "loss": 6.5717,
      "step": 33400
    },
    {
      "epoch": 2.2056887016065314,
      "grad_norm": 0.2534383237361908,
      "learning_rate": 0.00013252787288209992,
      "loss": 6.5356,
      "step": 33500
    },
    {
      "epoch": 2.2122728469844612,
      "grad_norm": 0.26733818650245667,
      "learning_rate": 0.00013143051531911158,
      "loss": 6.5893,
      "step": 33600
    },
    {
      "epoch": 2.2188569923623915,
      "grad_norm": 0.4342869222164154,
      "learning_rate": 0.00013033315775612324,
      "loss": 6.6374,
      "step": 33700
    },
    {
      "epoch": 2.2254411377403214,
      "grad_norm": 0.29378876090049744,
      "learning_rate": 0.00012923580019313493,
      "loss": 6.6321,
      "step": 33800
    },
    {
      "epoch": 2.232025283118251,
      "grad_norm": 0.27734774351119995,
      "learning_rate": 0.00012813844263014662,
      "loss": 6.586,
      "step": 33900
    },
    {
      "epoch": 2.238609428496181,
      "grad_norm": 0.25903719663619995,
      "learning_rate": 0.00012704108506715828,
      "loss": 6.5972,
      "step": 34000
    },
    {
      "epoch": 2.238609428496181,
      "eval_bleu": 17.383698123372895,
      "eval_loss": 6.508359432220459,
      "eval_runtime": 150.8498,
      "eval_samples_per_second": 6.629,
      "eval_steps_per_second": 0.829,
      "step": 34000
    },
    {
      "epoch": 2.2451935738741113,
      "grad_norm": 0.27790045738220215,
      "learning_rate": 0.00012594372750416997,
      "loss": 6.5758,
      "step": 34100
    },
    {
      "epoch": 2.251777719252041,
      "grad_norm": 0.39227941632270813,
      "learning_rate": 0.00012484636994118163,
      "loss": 6.4843,
      "step": 34200
    },
    {
      "epoch": 2.258361864629971,
      "grad_norm": 0.2030755877494812,
      "learning_rate": 0.00012374901237819332,
      "loss": 6.5567,
      "step": 34300
    },
    {
      "epoch": 2.264946010007901,
      "grad_norm": 0.31605684757232666,
      "learning_rate": 0.00012265165481520498,
      "loss": 6.5811,
      "step": 34400
    },
    {
      "epoch": 2.2715301553858307,
      "grad_norm": 0.33794328570365906,
      "learning_rate": 0.00012155429725221667,
      "loss": 6.5434,
      "step": 34500
    },
    {
      "epoch": 2.278114300763761,
      "grad_norm": 0.3159732520580292,
      "learning_rate": 0.00012045693968922834,
      "loss": 6.5862,
      "step": 34600
    },
    {
      "epoch": 2.284698446141691,
      "grad_norm": 0.3597940504550934,
      "learning_rate": 0.00011935958212624001,
      "loss": 6.5976,
      "step": 34700
    },
    {
      "epoch": 2.2912825915196207,
      "grad_norm": 0.26213595271110535,
      "learning_rate": 0.0001182622245632517,
      "loss": 6.5862,
      "step": 34800
    },
    {
      "epoch": 2.297866736897551,
      "grad_norm": 0.4060855805873871,
      "learning_rate": 0.00011716486700026336,
      "loss": 6.5942,
      "step": 34900
    },
    {
      "epoch": 2.304450882275481,
      "grad_norm": 0.291424423456192,
      "learning_rate": 0.00011606750943727504,
      "loss": 6.6299,
      "step": 35000
    },
    {
      "epoch": 2.304450882275481,
      "eval_bleu": 17.11818399025969,
      "eval_loss": 6.508036136627197,
      "eval_runtime": 143.0841,
      "eval_samples_per_second": 6.989,
      "eval_steps_per_second": 0.874,
      "step": 35000
    },
    {
      "epoch": 2.3110350276534106,
      "grad_norm": 0.2892968952655792,
      "learning_rate": 0.00011497015187428673,
      "loss": 6.5797,
      "step": 35100
    },
    {
      "epoch": 2.3176191730313405,
      "grad_norm": 0.24582421779632568,
      "learning_rate": 0.00011387279431129839,
      "loss": 6.5565,
      "step": 35200
    },
    {
      "epoch": 2.3242033184092703,
      "grad_norm": 0.28211668133735657,
      "learning_rate": 0.00011277543674831007,
      "loss": 6.5508,
      "step": 35300
    },
    {
      "epoch": 2.3307874637872006,
      "grad_norm": 0.27772602438926697,
      "learning_rate": 0.00011167807918532175,
      "loss": 6.5755,
      "step": 35400
    },
    {
      "epoch": 2.3373716091651304,
      "grad_norm": 0.28342342376708984,
      "learning_rate": 0.00011058072162233342,
      "loss": 6.5944,
      "step": 35500
    },
    {
      "epoch": 2.3439557545430603,
      "grad_norm": 0.29291948676109314,
      "learning_rate": 0.0001094833640593451,
      "loss": 6.5769,
      "step": 35600
    },
    {
      "epoch": 2.35053989992099,
      "grad_norm": 0.2956925630569458,
      "learning_rate": 0.00010838600649635677,
      "loss": 6.6017,
      "step": 35700
    },
    {
      "epoch": 2.3571240452989204,
      "grad_norm": 0.37355539202690125,
      "learning_rate": 0.00010728864893336846,
      "loss": 6.5819,
      "step": 35800
    },
    {
      "epoch": 2.3637081906768502,
      "grad_norm": 0.33881181478500366,
      "learning_rate": 0.00010619129137038012,
      "loss": 6.5962,
      "step": 35900
    },
    {
      "epoch": 2.37029233605478,
      "grad_norm": 0.29537075757980347,
      "learning_rate": 0.00010509393380739181,
      "loss": 6.6004,
      "step": 36000
    },
    {
      "epoch": 2.37029233605478,
      "eval_bleu": 17.416712514401123,
      "eval_loss": 6.50680685043335,
      "eval_runtime": 143.1001,
      "eval_samples_per_second": 6.988,
      "eval_steps_per_second": 0.874,
      "step": 36000
    },
    {
      "epoch": 2.37687648143271,
      "grad_norm": 0.22354991734027863,
      "learning_rate": 0.00010399657624440348,
      "loss": 6.6177,
      "step": 36100
    },
    {
      "epoch": 2.38346062681064,
      "grad_norm": 0.4649117588996887,
      "learning_rate": 0.00010289921868141514,
      "loss": 6.6007,
      "step": 36200
    },
    {
      "epoch": 2.39004477218857,
      "grad_norm": 0.17594191431999207,
      "learning_rate": 0.00010180186111842683,
      "loss": 6.514,
      "step": 36300
    },
    {
      "epoch": 2.3966289175665,
      "grad_norm": 0.4303792715072632,
      "learning_rate": 0.00010070450355543851,
      "loss": 6.5938,
      "step": 36400
    },
    {
      "epoch": 2.4032130629444297,
      "grad_norm": 0.2982768416404724,
      "learning_rate": 9.960714599245018e-05,
      "loss": 6.5927,
      "step": 36500
    },
    {
      "epoch": 2.4097972083223596,
      "grad_norm": 0.2539791464805603,
      "learning_rate": 9.852076200509174e-05,
      "loss": 6.5751,
      "step": 36600
    },
    {
      "epoch": 2.41638135370029,
      "grad_norm": 0.31906524300575256,
      "learning_rate": 9.742340444210342e-05,
      "loss": 6.5443,
      "step": 36700
    },
    {
      "epoch": 2.4229654990782197,
      "grad_norm": 0.3228653073310852,
      "learning_rate": 9.632604687911509e-05,
      "loss": 6.5419,
      "step": 36800
    },
    {
      "epoch": 2.4295496444561495,
      "grad_norm": 0.4118490517139435,
      "learning_rate": 9.522868931612677e-05,
      "loss": 6.5759,
      "step": 36900
    },
    {
      "epoch": 2.4361337898340794,
      "grad_norm": 0.32589882612228394,
      "learning_rate": 9.413133175313844e-05,
      "loss": 6.58,
      "step": 37000
    },
    {
      "epoch": 2.4361337898340794,
      "eval_bleu": 17.4496670667586,
      "eval_loss": 6.50558614730835,
      "eval_runtime": 143.8549,
      "eval_samples_per_second": 6.951,
      "eval_steps_per_second": 0.869,
      "step": 37000
    },
    {
      "epoch": 2.4427179352120096,
      "grad_norm": 0.3793269991874695,
      "learning_rate": 9.303397419015013e-05,
      "loss": 6.5237,
      "step": 37100
    },
    {
      "epoch": 2.4493020805899395,
      "grad_norm": 0.2696692645549774,
      "learning_rate": 9.19366166271618e-05,
      "loss": 6.6001,
      "step": 37200
    },
    {
      "epoch": 2.4558862259678693,
      "grad_norm": 0.29973897337913513,
      "learning_rate": 9.083925906417346e-05,
      "loss": 6.5461,
      "step": 37300
    },
    {
      "epoch": 2.462470371345799,
      "grad_norm": 0.26652058959007263,
      "learning_rate": 8.974190150118515e-05,
      "loss": 6.5249,
      "step": 37400
    },
    {
      "epoch": 2.4690545167237294,
      "grad_norm": 0.2615039050579071,
      "learning_rate": 8.864454393819683e-05,
      "loss": 6.5815,
      "step": 37500
    },
    {
      "epoch": 2.4756386621016593,
      "grad_norm": 0.20141486823558807,
      "learning_rate": 8.75471863752085e-05,
      "loss": 6.607,
      "step": 37600
    },
    {
      "epoch": 2.482222807479589,
      "grad_norm": 0.32314980030059814,
      "learning_rate": 8.644982881222017e-05,
      "loss": 6.618,
      "step": 37700
    },
    {
      "epoch": 2.488806952857519,
      "grad_norm": 0.2670010030269623,
      "learning_rate": 8.535247124923186e-05,
      "loss": 6.5441,
      "step": 37800
    },
    {
      "epoch": 2.495391098235449,
      "grad_norm": 0.42767849564552307,
      "learning_rate": 8.425511368624352e-05,
      "loss": 6.6182,
      "step": 37900
    },
    {
      "epoch": 2.501975243613379,
      "grad_norm": 0.28995198011398315,
      "learning_rate": 8.31577561232552e-05,
      "loss": 6.5529,
      "step": 38000
    },
    {
      "epoch": 2.501975243613379,
      "eval_bleu": 18.099555436475402,
      "eval_loss": 6.504946708679199,
      "eval_runtime": 141.2141,
      "eval_samples_per_second": 7.081,
      "eval_steps_per_second": 0.885,
      "step": 38000
    },
    {
      "epoch": 2.508559388991309,
      "grad_norm": 0.3006857931613922,
      "learning_rate": 8.206039856026689e-05,
      "loss": 6.5394,
      "step": 38100
    },
    {
      "epoch": 2.5151435343692388,
      "grad_norm": 0.2733702063560486,
      "learning_rate": 8.096304099727855e-05,
      "loss": 6.5679,
      "step": 38200
    },
    {
      "epoch": 2.521727679747169,
      "grad_norm": 0.25816601514816284,
      "learning_rate": 7.986568343429023e-05,
      "loss": 6.5457,
      "step": 38300
    },
    {
      "epoch": 2.528311825125099,
      "grad_norm": 0.440731406211853,
      "learning_rate": 7.876832587130191e-05,
      "loss": 6.5998,
      "step": 38400
    },
    {
      "epoch": 2.5348959705030287,
      "grad_norm": 0.2620949149131775,
      "learning_rate": 7.767096830831358e-05,
      "loss": 6.5673,
      "step": 38500
    },
    {
      "epoch": 2.5414801158809586,
      "grad_norm": 0.22010785341262817,
      "learning_rate": 7.657361074532526e-05,
      "loss": 6.625,
      "step": 38600
    },
    {
      "epoch": 2.5480642612588884,
      "grad_norm": 0.3050921559333801,
      "learning_rate": 7.547625318233693e-05,
      "loss": 6.6142,
      "step": 38700
    },
    {
      "epoch": 2.5546484066368187,
      "grad_norm": 0.2673923671245575,
      "learning_rate": 7.437889561934862e-05,
      "loss": 6.5648,
      "step": 38800
    },
    {
      "epoch": 2.5612325520147485,
      "grad_norm": 0.4358738958835602,
      "learning_rate": 7.328153805636028e-05,
      "loss": 6.564,
      "step": 38900
    },
    {
      "epoch": 2.5678166973926784,
      "grad_norm": 0.212173730134964,
      "learning_rate": 7.218418049337196e-05,
      "loss": 6.619,
      "step": 39000
    },
    {
      "epoch": 2.5678166973926784,
      "eval_bleu": 17.97034629180196,
      "eval_loss": 6.503938674926758,
      "eval_runtime": 154.4784,
      "eval_samples_per_second": 6.473,
      "eval_steps_per_second": 0.809,
      "step": 39000
    },
    {
      "epoch": 2.574400842770608,
      "grad_norm": 0.24072109162807465,
      "learning_rate": 7.108682293038364e-05,
      "loss": 6.6071,
      "step": 39100
    },
    {
      "epoch": 2.580984988148538,
      "grad_norm": 0.2441210299730301,
      "learning_rate": 6.99894653673953e-05,
      "loss": 6.5292,
      "step": 39200
    },
    {
      "epoch": 2.5875691335264683,
      "grad_norm": 0.27757638692855835,
      "learning_rate": 6.889210780440699e-05,
      "loss": 6.5733,
      "step": 39300
    },
    {
      "epoch": 2.594153278904398,
      "grad_norm": 0.1921195089817047,
      "learning_rate": 6.779475024141867e-05,
      "loss": 6.5834,
      "step": 39400
    },
    {
      "epoch": 2.600737424282328,
      "grad_norm": 0.27350062131881714,
      "learning_rate": 6.670836625406023e-05,
      "loss": 6.5646,
      "step": 39500
    },
    {
      "epoch": 2.6073215696602583,
      "grad_norm": 0.42789721488952637,
      "learning_rate": 6.561100869107189e-05,
      "loss": 6.5213,
      "step": 39600
    },
    {
      "epoch": 2.613905715038188,
      "grad_norm": 0.2228545993566513,
      "learning_rate": 6.451365112808358e-05,
      "loss": 6.5577,
      "step": 39700
    },
    {
      "epoch": 2.620489860416118,
      "grad_norm": 0.32933080196380615,
      "learning_rate": 6.341629356509525e-05,
      "loss": 6.5887,
      "step": 39800
    },
    {
      "epoch": 2.627074005794048,
      "grad_norm": 0.29596152901649475,
      "learning_rate": 6.231893600210693e-05,
      "loss": 6.6005,
      "step": 39900
    },
    {
      "epoch": 2.6336581511719777,
      "grad_norm": 0.34532564878463745,
      "learning_rate": 6.12215784391186e-05,
      "loss": 6.5699,
      "step": 40000
    },
    {
      "epoch": 2.6336581511719777,
      "eval_bleu": 17.911761602592378,
      "eval_loss": 6.5035223960876465,
      "eval_runtime": 148.1658,
      "eval_samples_per_second": 6.749,
      "eval_steps_per_second": 0.844,
      "step": 40000
    },
    {
      "epoch": 2.640242296549908,
      "grad_norm": 0.2672954797744751,
      "learning_rate": 6.013519445176016e-05,
      "loss": 6.5761,
      "step": 40100
    },
    {
      "epoch": 2.646826441927838,
      "grad_norm": 0.22832980751991272,
      "learning_rate": 5.903783688877184e-05,
      "loss": 6.5592,
      "step": 40200
    },
    {
      "epoch": 2.6534105873057676,
      "grad_norm": 0.31213313341140747,
      "learning_rate": 5.7940479325783516e-05,
      "loss": 6.5864,
      "step": 40300
    },
    {
      "epoch": 2.659994732683698,
      "grad_norm": 0.2919240891933441,
      "learning_rate": 5.684312176279519e-05,
      "loss": 6.5538,
      "step": 40400
    },
    {
      "epoch": 2.6665788780616277,
      "grad_norm": 0.3021470010280609,
      "learning_rate": 5.5745764199806865e-05,
      "loss": 6.5459,
      "step": 40500
    },
    {
      "epoch": 2.6731630234395576,
      "grad_norm": 0.30616018176078796,
      "learning_rate": 5.464840663681854e-05,
      "loss": 6.6054,
      "step": 40600
    },
    {
      "epoch": 2.6797471688174874,
      "grad_norm": 0.23753587901592255,
      "learning_rate": 5.3551049073830214e-05,
      "loss": 6.626,
      "step": 40700
    },
    {
      "epoch": 2.6863313141954173,
      "grad_norm": 0.2729153335094452,
      "learning_rate": 5.2453691510841895e-05,
      "loss": 6.5676,
      "step": 40800
    },
    {
      "epoch": 2.6929154595733475,
      "grad_norm": 0.28188857436180115,
      "learning_rate": 5.135633394785357e-05,
      "loss": 6.5612,
      "step": 40900
    },
    {
      "epoch": 2.6994996049512774,
      "grad_norm": 0.2671799957752228,
      "learning_rate": 5.025897638486525e-05,
      "loss": 6.6143,
      "step": 41000
    },
    {
      "epoch": 2.6994996049512774,
      "eval_bleu": 18.135450740955157,
      "eval_loss": 6.50238561630249,
      "eval_runtime": 145.4373,
      "eval_samples_per_second": 6.876,
      "eval_steps_per_second": 0.859,
      "step": 41000
    },
    {
      "epoch": 2.7060837503292072,
      "grad_norm": 0.28147512674331665,
      "learning_rate": 4.916161882187692e-05,
      "loss": 6.5868,
      "step": 41100
    },
    {
      "epoch": 2.712667895707137,
      "grad_norm": 0.28724610805511475,
      "learning_rate": 4.806426125888859e-05,
      "loss": 6.5421,
      "step": 41200
    },
    {
      "epoch": 2.719252041085067,
      "grad_norm": 0.5075046420097351,
      "learning_rate": 4.6966903695900274e-05,
      "loss": 6.5867,
      "step": 41300
    },
    {
      "epoch": 2.725836186462997,
      "grad_norm": 0.29808932542800903,
      "learning_rate": 4.586954613291195e-05,
      "loss": 6.54,
      "step": 41400
    },
    {
      "epoch": 2.732420331840927,
      "grad_norm": 0.3580438494682312,
      "learning_rate": 4.477218856992363e-05,
      "loss": 6.5208,
      "step": 41500
    },
    {
      "epoch": 2.739004477218857,
      "grad_norm": 0.29043689370155334,
      "learning_rate": 4.36748310069353e-05,
      "loss": 6.5701,
      "step": 41600
    },
    {
      "epoch": 2.745588622596787,
      "grad_norm": 0.3101261556148529,
      "learning_rate": 4.257747344394697e-05,
      "loss": 6.578,
      "step": 41700
    },
    {
      "epoch": 2.752172767974717,
      "grad_norm": 0.34640663862228394,
      "learning_rate": 4.1480115880958654e-05,
      "loss": 6.6078,
      "step": 41800
    },
    {
      "epoch": 2.758756913352647,
      "grad_norm": 0.25081777572631836,
      "learning_rate": 4.038275831797033e-05,
      "loss": 6.5854,
      "step": 41900
    },
    {
      "epoch": 2.7653410587305767,
      "grad_norm": 0.28759244084358215,
      "learning_rate": 3.928540075498201e-05,
      "loss": 6.5374,
      "step": 42000
    },
    {
      "epoch": 2.7653410587305767,
      "eval_bleu": 18.250874124919353,
      "eval_loss": 6.501983165740967,
      "eval_runtime": 142.4056,
      "eval_samples_per_second": 7.022,
      "eval_steps_per_second": 0.878,
      "step": 42000
    },
    {
      "epoch": 2.7719252041085065,
      "grad_norm": 0.3869841694831848,
      "learning_rate": 3.818804319199368e-05,
      "loss": 6.6134,
      "step": 42100
    },
    {
      "epoch": 2.778509349486437,
      "grad_norm": 0.2668474018573761,
      "learning_rate": 3.709068562900535e-05,
      "loss": 6.6021,
      "step": 42200
    },
    {
      "epoch": 2.7850934948643666,
      "grad_norm": 0.29636985063552856,
      "learning_rate": 3.599332806601703e-05,
      "loss": 6.6052,
      "step": 42300
    },
    {
      "epoch": 2.7916776402422965,
      "grad_norm": 0.3015274703502655,
      "learning_rate": 3.489597050302871e-05,
      "loss": 6.5496,
      "step": 42400
    },
    {
      "epoch": 2.7982617856202268,
      "grad_norm": 0.28209567070007324,
      "learning_rate": 3.379861294004039e-05,
      "loss": 6.5686,
      "step": 42500
    },
    {
      "epoch": 2.8048459309981566,
      "grad_norm": 0.2953789532184601,
      "learning_rate": 3.270125537705206e-05,
      "loss": 6.5742,
      "step": 42600
    },
    {
      "epoch": 2.8114300763760864,
      "grad_norm": 0.2799379229545593,
      "learning_rate": 3.160389781406373e-05,
      "loss": 6.6138,
      "step": 42700
    },
    {
      "epoch": 2.8180142217540163,
      "grad_norm": 0.2659095525741577,
      "learning_rate": 3.050654025107541e-05,
      "loss": 6.5755,
      "step": 42800
    },
    {
      "epoch": 2.824598367131946,
      "grad_norm": 0.2824844717979431,
      "learning_rate": 2.9409182688087086e-05,
      "loss": 6.5895,
      "step": 42900
    },
    {
      "epoch": 2.8311825125098764,
      "grad_norm": 0.3376552164554596,
      "learning_rate": 2.8311825125098764e-05,
      "loss": 6.5314,
      "step": 43000
    },
    {
      "epoch": 2.8311825125098764,
      "eval_bleu": 17.925855961466198,
      "eval_loss": 6.501310348510742,
      "eval_runtime": 147.5617,
      "eval_samples_per_second": 6.777,
      "eval_steps_per_second": 0.847,
      "step": 43000
    },
    {
      "epoch": 2.8377666578878062,
      "grad_norm": 0.3402669429779053,
      "learning_rate": 2.721446756211044e-05,
      "loss": 6.5947,
      "step": 43100
    },
    {
      "epoch": 2.844350803265736,
      "grad_norm": 0.32105106115341187,
      "learning_rate": 2.6117109999122116e-05,
      "loss": 6.5816,
      "step": 43200
    },
    {
      "epoch": 2.850934948643666,
      "grad_norm": 0.21708115935325623,
      "learning_rate": 2.501975243613379e-05,
      "loss": 6.5928,
      "step": 43300
    },
    {
      "epoch": 2.8575190940215958,
      "grad_norm": 0.22116585075855255,
      "learning_rate": 2.3922394873145465e-05,
      "loss": 6.5667,
      "step": 43400
    },
    {
      "epoch": 2.864103239399526,
      "grad_norm": 0.3272826075553894,
      "learning_rate": 2.2825037310157143e-05,
      "loss": 6.5771,
      "step": 43500
    },
    {
      "epoch": 2.870687384777456,
      "grad_norm": 0.3283160328865051,
      "learning_rate": 2.1727679747168818e-05,
      "loss": 6.5089,
      "step": 43600
    },
    {
      "epoch": 2.8772715301553857,
      "grad_norm": 0.31806454062461853,
      "learning_rate": 2.0630322184180492e-05,
      "loss": 6.5326,
      "step": 43700
    },
    {
      "epoch": 2.883855675533316,
      "grad_norm": 0.30423659086227417,
      "learning_rate": 1.953296462119217e-05,
      "loss": 6.6109,
      "step": 43800
    },
    {
      "epoch": 2.890439820911246,
      "grad_norm": 0.3039707541465759,
      "learning_rate": 1.8435607058203845e-05,
      "loss": 6.5981,
      "step": 43900
    },
    {
      "epoch": 2.8970239662891757,
      "grad_norm": 0.30607888102531433,
      "learning_rate": 1.7338249495215522e-05,
      "loss": 6.5501,
      "step": 44000
    },
    {
      "epoch": 2.8970239662891757,
      "eval_bleu": 18.17441361669806,
      "eval_loss": 6.501299858093262,
      "eval_runtime": 139.2416,
      "eval_samples_per_second": 7.182,
      "eval_steps_per_second": 0.898,
      "step": 44000
    },
    {
      "epoch": 2.9036081116671055,
      "grad_norm": 0.2519637644290924,
      "learning_rate": 1.62408919322272e-05,
      "loss": 6.5048,
      "step": 44100
    },
    {
      "epoch": 2.9101922570450354,
      "grad_norm": 0.22471430897712708,
      "learning_rate": 1.5143534369238873e-05,
      "loss": 6.6083,
      "step": 44200
    },
    {
      "epoch": 2.9167764024229657,
      "grad_norm": 0.27725449204444885,
      "learning_rate": 1.4057150381880433e-05,
      "loss": 6.5202,
      "step": 44300
    },
    {
      "epoch": 2.9233605478008955,
      "grad_norm": 0.3864752948284149,
      "learning_rate": 1.2959792818892108e-05,
      "loss": 6.5554,
      "step": 44400
    },
    {
      "epoch": 2.9299446931788253,
      "grad_norm": 0.2261798083782196,
      "learning_rate": 1.1862435255903784e-05,
      "loss": 6.5196,
      "step": 44500
    },
    {
      "epoch": 2.936528838556755,
      "grad_norm": 0.22376978397369385,
      "learning_rate": 1.0765077692915458e-05,
      "loss": 6.5702,
      "step": 44600
    },
    {
      "epoch": 2.943112983934685,
      "grad_norm": 0.5284765958786011,
      "learning_rate": 9.667720129927136e-06,
      "loss": 6.5757,
      "step": 44700
    },
    {
      "epoch": 2.9496971293126153,
      "grad_norm": 0.2826176583766937,
      "learning_rate": 8.570362566938812e-06,
      "loss": 6.548,
      "step": 44800
    },
    {
      "epoch": 2.956281274690545,
      "grad_norm": 0.30728232860565186,
      "learning_rate": 7.473005003950487e-06,
      "loss": 6.5747,
      "step": 44900
    },
    {
      "epoch": 2.962865420068475,
      "grad_norm": 0.24715834856033325,
      "learning_rate": 6.375647440962164e-06,
      "loss": 6.5751,
      "step": 45000
    },
    {
      "epoch": 2.962865420068475,
      "eval_bleu": 18.154659902222047,
      "eval_loss": 6.501039028167725,
      "eval_runtime": 146.1088,
      "eval_samples_per_second": 6.844,
      "eval_steps_per_second": 0.856,
      "step": 45000
    }
  ],
  "logging_steps": 100,
  "max_steps": 45564,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.784422540981043e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
